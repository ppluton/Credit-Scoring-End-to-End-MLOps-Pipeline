{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîß Preprocessing & Feature Engineering - Home Credit Default Risk\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "1. Charger les donn√©es agr√©g√©es (train_aggregated.csv, test_aggregated.csv)\n",
    "2. Cr√©er des features \"Has_History\" avant imputation\n",
    "3. Traitement strat√©gique des valeurs manquantes\n",
    "4. Encodage des variables cat√©gorielles\n",
    "5. Feature engineering avanc√© (ratios, interactions)\n",
    "6. Gestion des outliers\n",
    "7. Scaling/Normalisation\n",
    "8. Sauvegarde des datasets preprocessed\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports r√©ussis\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configuration\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "\n",
    "print(\"‚úÖ Imports r√©ussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des Donn√©es Agr√©g√©es\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Chargement des donn√©es agr√©g√©es...\n",
      "‚úÖ Train shape: (307511, 305)\n",
      "‚úÖ Test shape: (48744, 304)\n",
      "\n",
      "üìä Distribution de TARGET:\n",
      "TARGET\n",
      "0    282686\n",
      "1     24825\n",
      "Name: count, dtype: int64\n",
      "Taux de d√©faut: 8.07%\n"
     ]
    }
   ],
   "source": [
    "# Chemins\n",
    "DATA_PATH = Path(\"../data\")\n",
    "\n",
    "# Charger les donn√©es agr√©g√©es du Notebook 1\n",
    "print(\"üìÇ Chargement des donn√©es agr√©g√©es...\")\n",
    "train = pd.read_csv(DATA_PATH / \"train_aggregated.csv\")\n",
    "test = pd.read_csv(DATA_PATH / \"test_aggregated.csv\")\n",
    "\n",
    "print(f\"‚úÖ Train shape: {train.shape}\")\n",
    "print(f\"‚úÖ Test shape: {test.shape}\")\n",
    "\n",
    "# S√©parer la variable cible\n",
    "y_train = train[\"TARGET\"]\n",
    "train_ids = train[\"SK_ID_CURR\"]\n",
    "test_ids = test[\"SK_ID_CURR\"]\n",
    "\n",
    "print(f\"\\nüìä Distribution de TARGET:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Taux de d√©faut: {y_train.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse Pr√©liminaire des Valeurs Manquantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä ANALYSE DES VALEURS MANQUANTES - Train\n",
      "============================================================\n",
      "Colonnes avec NaN: 250/305\n",
      "\n",
      "R√©partition par % de NaN:\n",
      "  - >80% NaN: 8 colonnes\n",
      "  - 50-80% NaN: 79 colonnes\n",
      "  - 30-50% NaN: 11 colonnes\n",
      "  - <30% NaN: 152 colonnes\n",
      "\n",
      "üìã Top 20 colonnes avec le plus de NaN:\n",
      "                                                                      Column  \\\n",
      "CC_AMT_PAYMENT_CURRENT_MEAN_MEAN            CC_AMT_PAYMENT_CURRENT_MEAN_MEAN   \n",
      "CC_AMT_PAYMENT_CURRENT_MAX_MEAN              CC_AMT_PAYMENT_CURRENT_MAX_MEAN   \n",
      "CC_AMT_PAYMENT_CURRENT_MEAN_MAX              CC_AMT_PAYMENT_CURRENT_MEAN_MAX   \n",
      "CC_AMT_PAYMENT_CURRENT_MAX_MAX                CC_AMT_PAYMENT_CURRENT_MAX_MAX   \n",
      "CC_AMT_DRAWINGS_ATM_CURRENT_MAX_MAX      CC_AMT_DRAWINGS_ATM_CURRENT_MAX_MAX   \n",
      "CC_AMT_DRAWINGS_ATM_CURRENT_MAX_MEAN    CC_AMT_DRAWINGS_ATM_CURRENT_MAX_MEAN   \n",
      "CC_AMT_DRAWINGS_ATM_CURRENT_MEAN_MAX    CC_AMT_DRAWINGS_ATM_CURRENT_MEAN_MAX   \n",
      "CC_AMT_DRAWINGS_ATM_CURRENT_MEAN_MEAN  CC_AMT_DRAWINGS_ATM_CURRENT_MEAN_MEAN   \n",
      "CC_AMT_PAYMENT_CURRENT_SUM_MAX                CC_AMT_PAYMENT_CURRENT_SUM_MAX   \n",
      "CC_MONTHS_BALANCE_MAX_MAX                          CC_MONTHS_BALANCE_MAX_MAX   \n",
      "CC_SK_DPD_DEF_MAX_MEAN                                CC_SK_DPD_DEF_MAX_MEAN   \n",
      "CC_AMT_CREDIT_LIMIT_ACTUAL_MEAN_MAX      CC_AMT_CREDIT_LIMIT_ACTUAL_MEAN_MAX   \n",
      "CC_SK_DPD_MEAN_MAX                                        CC_SK_DPD_MEAN_MAX   \n",
      "CC_SK_DPD_MEAN_MEAN                                      CC_SK_DPD_MEAN_MEAN   \n",
      "CC_SK_DPD_MAX_MAX                                          CC_SK_DPD_MAX_MAX   \n",
      "CC_SK_DPD_MAX_MEAN                                        CC_SK_DPD_MAX_MEAN   \n",
      "CC_MONTHS_BALANCE_MAX_MEAN                        CC_MONTHS_BALANCE_MAX_MEAN   \n",
      "CC_MONTHS_BALANCE_MIN_MAX                          CC_MONTHS_BALANCE_MIN_MAX   \n",
      "CC_MONTHS_BALANCE_SIZE_MEAN                      CC_MONTHS_BALANCE_SIZE_MEAN   \n",
      "CC_MONTHS_BALANCE_SIZE_MAX                        CC_MONTHS_BALANCE_SIZE_MAX   \n",
      "\n",
      "                                       Missing_Count  Missing_Percent    Dtype  \n",
      "CC_AMT_PAYMENT_CURRENT_MEAN_MEAN              254669            82.82  float64  \n",
      "CC_AMT_PAYMENT_CURRENT_MAX_MEAN               254669            82.82  float64  \n",
      "CC_AMT_PAYMENT_CURRENT_MEAN_MAX               254669            82.82  float64  \n",
      "CC_AMT_PAYMENT_CURRENT_MAX_MAX                254669            82.82  float64  \n",
      "CC_AMT_DRAWINGS_ATM_CURRENT_MAX_MAX           254581            82.79  float64  \n",
      "CC_AMT_DRAWINGS_ATM_CURRENT_MAX_MEAN          254581            82.79  float64  \n",
      "CC_AMT_DRAWINGS_ATM_CURRENT_MEAN_MAX          254581            82.79  float64  \n",
      "CC_AMT_DRAWINGS_ATM_CURRENT_MEAN_MEAN         254581            82.79  float64  \n",
      "CC_AMT_PAYMENT_CURRENT_SUM_MAX                229577            74.66  float64  \n",
      "CC_MONTHS_BALANCE_MAX_MAX                     229577            74.66  float64  \n",
      "CC_SK_DPD_DEF_MAX_MEAN                        229577            74.66  float64  \n",
      "CC_AMT_CREDIT_LIMIT_ACTUAL_MEAN_MAX           229577            74.66  float64  \n",
      "CC_SK_DPD_MEAN_MAX                            229577            74.66  float64  \n",
      "CC_SK_DPD_MEAN_MEAN                           229577            74.66  float64  \n",
      "CC_SK_DPD_MAX_MAX                             229577            74.66  float64  \n",
      "CC_SK_DPD_MAX_MEAN                            229577            74.66  float64  \n",
      "CC_MONTHS_BALANCE_MAX_MEAN                    229577            74.66  float64  \n",
      "CC_MONTHS_BALANCE_MIN_MAX                     229577            74.66  float64  \n",
      "CC_MONTHS_BALANCE_SIZE_MEAN                   229577            74.66  float64  \n",
      "CC_MONTHS_BALANCE_SIZE_MAX                    229577            74.66  float64  \n"
     ]
    }
   ],
   "source": [
    "# Fonction pour analyser les NaN\n",
    "def analyze_missing(df, name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Analyse d√©taill√©e des valeurs manquantes\n",
    "    \"\"\"\n",
    "    missing = pd.DataFrame(\n",
    "        {\n",
    "            \"Column\": df.columns,\n",
    "            \"Missing_Count\": df.isnull().sum(),\n",
    "            \"Missing_Percent\": (df.isnull().sum() / len(df) * 100).round(2),\n",
    "            \"Dtype\": df.dtypes,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    missing = missing[missing[\"Missing_Count\"] > 0].sort_values(\n",
    "        \"Missing_Percent\", ascending=False\n",
    "    )\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"üìä ANALYSE DES VALEURS MANQUANTES - {name}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"Colonnes avec NaN: {len(missing)}/{len(df.columns)}\")\n",
    "    print(f\"\\nR√©partition par % de NaN:\")\n",
    "    print(f\"  - >80% NaN: {len(missing[missing['Missing_Percent'] > 80])} colonnes\")\n",
    "    print(\n",
    "        f\"  - 50-80% NaN: {len(missing[(missing['Missing_Percent'] > 50) & (missing['Missing_Percent'] <= 80)])} colonnes\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  - 30-50% NaN: {len(missing[(missing['Missing_Percent'] > 30) & (missing['Missing_Percent'] <= 50)])} colonnes\"\n",
    "    )\n",
    "    print(f\"  - <30% NaN: {len(missing[missing['Missing_Percent'] <= 30])} colonnes\")\n",
    "\n",
    "    return missing\n",
    "\n",
    "\n",
    "# Analyser les NaN\n",
    "missing_train = analyze_missing(train, \"Train\")\n",
    "\n",
    "print(\"\\nüìã Top 20 colonnes avec le plus de NaN:\")\n",
    "print(missing_train.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cr√©ation des Features \"Has_History\"\n",
    "\n",
    "**Strat√©gie Cl√©:** Avant de remplir les NaN, on cr√©e des indicateurs binaires qui capturent l'**absence** d'historique, car c'est une information importante !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Cr√©ation des features 'Has_History'...\n",
      "\n",
      "‚úÖ HAS_BUREAU: 85.7% des clients ont cet historique\n",
      "‚úÖ HAS_PREV_APP: 94.5% des clients ont cet historique\n",
      "‚úÖ HAS_CREDIT_CARD: 17.2% des clients ont cet historique\n",
      "‚úÖ HAS_POS_CASH: 93.3% des clients ont cet historique\n",
      "‚úÖ HAS_INSTALLMENTS: 94.1% des clients ont cet historique\n",
      "\n",
      "üìä Nouvelles features cr√©√©es: 5\n",
      "Train shape: (307511, 310)\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Cr√©ation des features 'Has_History'...\\n\")\n",
    "\n",
    "# Liste des features \"Has_History\" √† cr√©er\n",
    "history_features = {\n",
    "    \"HAS_BUREAU\": \"BUREAU_SK_ID_BUREAU_COUNT\",\n",
    "    \"HAS_PREV_APP\": \"PREV_AMT_ANNUITY_MEAN\",\n",
    "    \"HAS_CREDIT_CARD\": \"CC_AMT_PAYMENT_CURRENT_MEAN_MEAN\",\n",
    "    \"HAS_POS_CASH\": \"POS_MONTHS_BALANCE_MIN_MEAN\",\n",
    "    \"HAS_INSTALLMENTS\": \"INSTAL_PAYMENT_DIFF_MEAN_MEAN\",\n",
    "}\n",
    "\n",
    "# Cr√©er les features pour train et test\n",
    "for new_feature, base_feature in history_features.items():\n",
    "    if base_feature in train.columns:\n",
    "        # 1 si la feature existe (pas NaN), 0 sinon\n",
    "        train[new_feature] = (~train[base_feature].isna()).astype(int)\n",
    "        test[new_feature] = (~test[base_feature].isna()).astype(int)\n",
    "\n",
    "        # Statistiques\n",
    "        has_pct = train[new_feature].mean() * 100\n",
    "        print(f\"‚úÖ {new_feature}: {has_pct:.1f}% des clients ont cet historique\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è {new_feature}: colonne {base_feature} introuvable\")\n",
    "\n",
    "print(f\"\\nüìä Nouvelles features cr√©√©es: {len(history_features)}\")\n",
    "print(f\"Train shape: {train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identification et Suppression des Colonnes Peu Informatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Identification des colonnes √† supprimer (>80% NaN)...\n",
      "\n",
      "üìã Colonnes √† supprimer: 8\n",
      "\n",
      "Exemples:\n",
      "  - CC_AMT_DRAWINGS_ATM_CURRENT_MEAN_MEAN: 82.8% NaN\n",
      "  - CC_AMT_DRAWINGS_ATM_CURRENT_MEAN_MAX: 82.8% NaN\n",
      "  - CC_AMT_DRAWINGS_ATM_CURRENT_MAX_MEAN: 82.8% NaN\n",
      "  - CC_AMT_DRAWINGS_ATM_CURRENT_MAX_MAX: 82.8% NaN\n",
      "  - CC_AMT_PAYMENT_CURRENT_MEAN_MEAN: 82.8% NaN\n",
      "  - CC_AMT_PAYMENT_CURRENT_MEAN_MAX: 82.8% NaN\n",
      "  - CC_AMT_PAYMENT_CURRENT_MAX_MEAN: 82.8% NaN\n",
      "  - CC_AMT_PAYMENT_CURRENT_MAX_MAX: 82.8% NaN\n",
      "\n",
      "‚úÖ Shape apr√®s suppression:\n",
      "   Train: (307511, 310) ‚Üí (307511, 302)\n",
      "   Test: (48744, 309) ‚Üí (48744, 301)\n",
      "   Colonnes supprim√©es: 8\n"
     ]
    }
   ],
   "source": [
    "# Strat√©gie: Supprimer les colonnes avec >80% de NaN\n",
    "print(\"üóëÔ∏è Identification des colonnes √† supprimer (>80% NaN)...\\n\")\n",
    "\n",
    "threshold_drop = 0.80\n",
    "cols_to_drop = []\n",
    "\n",
    "for col in train.columns:\n",
    "    if col in [\"SK_ID_CURR\", \"TARGET\"]:  # Ne jamais supprimer ces colonnes\n",
    "        continue\n",
    "\n",
    "    missing_pct = train[col].isna().sum() / len(train)\n",
    "\n",
    "    if missing_pct > threshold_drop:\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "print(f\"üìã Colonnes √† supprimer: {len(cols_to_drop)}\")\n",
    "print(f\"\\nExemples:\")\n",
    "for col in cols_to_drop[:10]:\n",
    "    missing_pct = train[col].isna().sum() / len(train) * 100\n",
    "    print(f\"  - {col}: {missing_pct:.1f}% NaN\")\n",
    "\n",
    "# Supprimer les colonnes\n",
    "train_cleaned = train.drop(columns=cols_to_drop)\n",
    "test_cleaned = test.drop(columns=[col for col in cols_to_drop if col in test.columns])\n",
    "\n",
    "print(f\"\\n‚úÖ Shape apr√®s suppression:\")\n",
    "print(f\"   Train: {train.shape} ‚Üí {train_cleaned.shape}\")\n",
    "print(f\"   Test: {test.shape} ‚Üí {test_cleaned.shape}\")\n",
    "print(f\"   Colonnes supprim√©es: {len(cols_to_drop)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. S√©paration des Types de Colonnes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Identification des types de colonnes...\n",
      "\n",
      "üìä R√©partition des colonnes:\n",
      "   - ID: 1\n",
      "   - Target: 1\n",
      "   - Cat√©gorielles: 16\n",
      "   - Num√©riques: 284\n",
      "   - TOTAL: 302\n",
      "\n",
      "üìã Colonnes cat√©gorielles:\n",
      "   - NAME_CONTRACT_TYPE: 2 valeurs uniques\n",
      "   - CODE_GENDER: 3 valeurs uniques\n",
      "   - FLAG_OWN_CAR: 2 valeurs uniques\n",
      "   - FLAG_OWN_REALTY: 2 valeurs uniques\n",
      "   - NAME_TYPE_SUITE: 7 valeurs uniques\n",
      "   - NAME_INCOME_TYPE: 8 valeurs uniques\n",
      "   - NAME_EDUCATION_TYPE: 5 valeurs uniques\n",
      "   - NAME_FAMILY_STATUS: 6 valeurs uniques\n",
      "   - NAME_HOUSING_TYPE: 6 valeurs uniques\n",
      "   - OCCUPATION_TYPE: 18 valeurs uniques\n",
      "   - WEEKDAY_APPR_PROCESS_START: 7 valeurs uniques\n",
      "   - ORGANIZATION_TYPE: 58 valeurs uniques\n",
      "   - FONDKAPREMONT_MODE: 4 valeurs uniques\n",
      "   - HOUSETYPE_MODE: 3 valeurs uniques\n",
      "   - WALLSMATERIAL_MODE: 7 valeurs uniques\n",
      "   - EMERGENCYSTATE_MODE: 2 valeurs uniques\n"
     ]
    }
   ],
   "source": [
    "# Identifier les colonnes par type\n",
    "print(\"üîç Identification des types de colonnes...\\n\")\n",
    "\n",
    "# Colonnes √† ne pas traiter\n",
    "id_cols = [\"SK_ID_CURR\"]\n",
    "target_col = [\"TARGET\"]\n",
    "\n",
    "# Colonnes cat√©gorielles (type object)\n",
    "categorical_cols = train_cleaned.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categorical_cols = [col for col in categorical_cols if col not in id_cols]\n",
    "\n",
    "# Colonnes num√©riques\n",
    "numeric_cols = train_cleaned.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [col for col in numeric_cols if col not in id_cols + target_col]\n",
    "\n",
    "print(f\"üìä R√©partition des colonnes:\")\n",
    "print(f\"   - ID: {len(id_cols)}\")\n",
    "print(f\"   - Target: {len(target_col)}\")\n",
    "print(f\"   - Cat√©gorielles: {len(categorical_cols)}\")\n",
    "print(f\"   - Num√©riques: {len(numeric_cols)}\")\n",
    "print(\n",
    "    f\"   - TOTAL: {len(id_cols) + len(target_col) + len(categorical_cols) + len(numeric_cols)}\"\n",
    ")\n",
    "\n",
    "if categorical_cols:\n",
    "    print(f\"\\nüìã Colonnes cat√©gorielles:\")\n",
    "    for col in categorical_cols:\n",
    "        n_unique = train_cleaned[col].nunique()\n",
    "        print(f\"   - {col}: {n_unique} valeurs uniques\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Encodage des Variables Cat√©gorielles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Encodage des variables cat√©gorielles (One-Hot Encoding)...\n",
      "\n",
      "‚úÖ Shape apr√®s encodage:\n",
      "   Train: (307511, 302) ‚Üí (307511, 410)\n",
      "   Test: (48744, 301) ‚Üí (48744, 410)\n",
      "   Nouvelles colonnes cr√©√©es: 124\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding pour les variables cat√©gorielles\n",
    "if categorical_cols:\n",
    "    print(\"üîß Encodage des variables cat√©gorielles (One-Hot Encoding)...\\n\")\n",
    "\n",
    "    # Appliquer One-Hot Encoding\n",
    "    train_encoded = pd.get_dummies(\n",
    "        train_cleaned, columns=categorical_cols, drop_first=True\n",
    "    )\n",
    "    test_encoded = pd.get_dummies(\n",
    "        test_cleaned, columns=categorical_cols, drop_first=True\n",
    "    )\n",
    "\n",
    "    # Aligner les colonnes entre train et test\n",
    "    train_encoded, test_encoded = train_encoded.align(\n",
    "        test_encoded, join=\"left\", axis=1, fill_value=0\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Shape apr√®s encodage:\")\n",
    "    print(f\"   Train: {train_cleaned.shape} ‚Üí {train_encoded.shape}\")\n",
    "    print(f\"   Test: {test_cleaned.shape} ‚Üí {test_encoded.shape}\")\n",
    "    print(\n",
    "        f\"   Nouvelles colonnes cr√©√©es: {train_encoded.shape[1] - train_cleaned.shape[1] + len(categorical_cols)}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Aucune variable cat√©gorielle √† encoder\")\n",
    "    train_encoded = train_cleaned.copy()\n",
    "    test_encoded = test_cleaned.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Imputation Strat√©gique des Valeurs Manquantes\n",
    "\n",
    "### Strat√©gie d'Imputation:\n",
    "\n",
    "1. **Colonnes de montants (AMT, SUM):** Remplir avec 0 (pas de cr√©dit = 0‚Ç¨)\n",
    "2. **Colonnes de comptage (COUNT, CNT):** Remplir avec 0\n",
    "3. **Colonnes de dates (DAYS):** Remplir avec -999 (valeur sentinelle)\n",
    "4. **Colonnes de moyennes/ratios (MEAN, AVG):** Remplir avec la m√©diane\n",
    "5. **Autres colonnes num√©riques:** Remplir avec la m√©diane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Imputation strat√©gique des valeurs manquantes...\n",
      "\n",
      "‚úÖ Colonnes de montants (remplies avec 0): 122\n",
      "‚úÖ Colonnes de comptage (remplies avec 0): 11\n",
      "‚úÖ Colonnes de dates (remplies avec -999): 29\n",
      "‚úÖ Colonnes de moyennes (remplies avec m√©diane): 56\n",
      "‚úÖ Autres colonnes num√©riques (remplies avec m√©diane): 77\n",
      "\n",
      "üìä V√©rification post-imputation:\n",
      "   Train - NaN restants: 0\n",
      "   Test - NaN restants: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Imputation strat√©gique des valeurs manquantes...\\n\")\n",
    "\n",
    "# Cr√©er des copies pour l'imputation\n",
    "train_imputed = train_encoded.copy()\n",
    "test_imputed = test_encoded.copy()\n",
    "\n",
    "# Identifier les colonnes num√©riques (mise √† jour apr√®s encodage)\n",
    "numeric_cols_updated = train_imputed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols_updated = [\n",
    "    col for col in numeric_cols_updated if col not in id_cols + target_col\n",
    "]\n",
    "\n",
    "# 1. Colonnes de montants ‚Üí 0\n",
    "amount_cols = [\n",
    "    col\n",
    "    for col in numeric_cols_updated\n",
    "    if any(\n",
    "        x in col\n",
    "        for x in [\"AMT\", \"SUM\", \"CREDIT\", \"PAYMENT\", \"BALANCE\", \"GOODS\", \"PRICE\"]\n",
    "    )\n",
    "]\n",
    "if amount_cols:\n",
    "    train_imputed[amount_cols] = train_imputed[amount_cols].fillna(0)\n",
    "    test_imputed[amount_cols] = test_imputed[amount_cols].fillna(0)\n",
    "    print(f\"‚úÖ Colonnes de montants (remplies avec 0): {len(amount_cols)}\")\n",
    "\n",
    "# 2. Colonnes de comptage ‚Üí 0\n",
    "count_cols = [\n",
    "    col\n",
    "    for col in numeric_cols_updated\n",
    "    if any(x in col for x in [\"COUNT\", \"CNT\", \"NUMBER\", \"NUM\"])\n",
    "]\n",
    "count_cols = [\n",
    "    col for col in count_cols if col not in amount_cols\n",
    "]  # √âviter les doublons\n",
    "if count_cols:\n",
    "    train_imputed[count_cols] = train_imputed[count_cols].fillna(0)\n",
    "    test_imputed[count_cols] = test_imputed[count_cols].fillna(0)\n",
    "    print(f\"‚úÖ Colonnes de comptage (remplies avec 0): {len(count_cols)}\")\n",
    "\n",
    "# 3. Colonnes de dates ‚Üí -999\n",
    "date_cols = [col for col in numeric_cols_updated if \"DAYS\" in col]\n",
    "if date_cols:\n",
    "    train_imputed[date_cols] = train_imputed[date_cols].fillna(-999)\n",
    "    test_imputed[date_cols] = test_imputed[date_cols].fillna(-999)\n",
    "    print(f\"‚úÖ Colonnes de dates (remplies avec -999): {len(date_cols)}\")\n",
    "\n",
    "# 4. Colonnes de moyennes/ratios ‚Üí m√©diane\n",
    "mean_cols = [\n",
    "    col\n",
    "    for col in numeric_cols_updated\n",
    "    if any(x in col for x in [\"MEAN\", \"AVG\", \"MEDIAN\", \"MEDI\", \"MODE\"])\n",
    "]\n",
    "mean_cols = [\n",
    "    col for col in mean_cols if col not in amount_cols + count_cols + date_cols\n",
    "]\n",
    "if mean_cols:\n",
    "    for col in mean_cols:\n",
    "        median_val = train_imputed[col].median()\n",
    "        train_imputed[col] = train_imputed[col].fillna(median_val)\n",
    "        test_imputed[col] = test_imputed[col].fillna(median_val)\n",
    "    print(f\"‚úÖ Colonnes de moyennes (remplies avec m√©diane): {len(mean_cols)}\")\n",
    "\n",
    "# 5. Autres colonnes ‚Üí m√©diane\n",
    "remaining_cols = [\n",
    "    col\n",
    "    for col in numeric_cols_updated\n",
    "    if col not in amount_cols + count_cols + date_cols + mean_cols\n",
    "]\n",
    "if remaining_cols:\n",
    "    for col in remaining_cols:\n",
    "        median_val = train_imputed[col].median()\n",
    "        train_imputed[col] = train_imputed[col].fillna(median_val)\n",
    "        test_imputed[col] = test_imputed[col].fillna(median_val)\n",
    "    print(\n",
    "        f\"‚úÖ Autres colonnes num√©riques (remplies avec m√©diane): {len(remaining_cols)}\"\n",
    "    )\n",
    "\n",
    "# V√©rification finale\n",
    "print(f\"\\nüìä V√©rification post-imputation:\")\n",
    "print(f\"   Train - NaN restants: {train_imputed.isnull().sum().sum()}\")\n",
    "print(f\"   Test - NaN restants: {test_imputed.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Engineering Avanc√©\n",
    "\n",
    "### Cr√©ation de Features D√©riv√©es:\n",
    "\n",
    "1. **Ratios financiers** (Credit/Income, Annuity/Income, etc.)\n",
    "2. **Features temporelles** (√Çge en ann√©es, anciennet√© emploi)\n",
    "3. **Interactions importantes**\n",
    "4. **Features agr√©g√©es** (scores moyens, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Feature Engineering avanc√©...\n",
      "\n",
      "üí∞ Cr√©ation des ratios financiers...\n",
      "  ‚úÖ CREDIT_INCOME_RATIO\n",
      "  ‚úÖ ANNUITY_INCOME_RATIO\n",
      "  ‚úÖ GOODS_CREDIT_RATIO\n",
      "  ‚úÖ CREDIT_GOODS_RATIO\n",
      "\n",
      "üìÖ Cr√©ation des features temporelles...\n",
      "  ‚úÖ AGE_YEARS\n",
      "  ‚úÖ EMPLOYMENT_YEARS\n",
      "\n",
      "üìä Cr√©ation des features de scores...\n",
      "  ‚úÖ EXT_SOURCE_MEAN\n",
      "  ‚úÖ EXT_SOURCE_PROD\n",
      "\n",
      "üë• Cr√©ation des features d√©mographiques...\n",
      "  ‚úÖ INCOME_PER_PERSON\n",
      "  ‚úÖ CHILDREN_RATIO\n",
      "\n",
      "üè¶ Cr√©ation des features bureau...\n",
      "  ‚úÖ BUREAU_DEBT_INCOME_RATIO\n",
      "\n",
      "‚úÖ Total de nouvelles features cr√©√©es: 11\n",
      "   Shape finale: (307511, 421)\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Feature Engineering avanc√©...\\n\")\n",
    "\n",
    "# Copies pour le feature engineering\n",
    "train_fe = train_imputed.copy()\n",
    "test_fe = test_imputed.copy()\n",
    "\n",
    "# Compteur de nouvelles features\n",
    "new_features_count = 0\n",
    "\n",
    "# 1. RATIOS FINANCIERS\n",
    "print(\"üí∞ Cr√©ation des ratios financiers...\")\n",
    "\n",
    "# Ratio Cr√©dit / Revenu\n",
    "if \"AMT_CREDIT\" in train_fe.columns and \"AMT_INCOME_TOTAL\" in train_fe.columns:\n",
    "    train_fe[\"CREDIT_INCOME_RATIO\"] = train_fe[\"AMT_CREDIT\"] / (\n",
    "        train_fe[\"AMT_INCOME_TOTAL\"] + 1\n",
    "    )\n",
    "    test_fe[\"CREDIT_INCOME_RATIO\"] = test_fe[\"AMT_CREDIT\"] / (\n",
    "        test_fe[\"AMT_INCOME_TOTAL\"] + 1\n",
    "    )\n",
    "    new_features_count += 1\n",
    "    print(\"  ‚úÖ CREDIT_INCOME_RATIO\")\n",
    "\n",
    "# Ratio Annuit√© / Revenu\n",
    "if \"AMT_ANNUITY\" in train_fe.columns and \"AMT_INCOME_TOTAL\" in train_fe.columns:\n",
    "    train_fe[\"ANNUITY_INCOME_RATIO\"] = train_fe[\"AMT_ANNUITY\"] / (\n",
    "        train_fe[\"AMT_INCOME_TOTAL\"] + 1\n",
    "    )\n",
    "    test_fe[\"ANNUITY_INCOME_RATIO\"] = test_fe[\"AMT_ANNUITY\"] / (\n",
    "        test_fe[\"AMT_INCOME_TOTAL\"] + 1\n",
    "    )\n",
    "    new_features_count += 1\n",
    "    print(\"  ‚úÖ ANNUITY_INCOME_RATIO\")\n",
    "\n",
    "# Ratio Prix du bien / Cr√©dit\n",
    "if \"AMT_GOODS_PRICE\" in train_fe.columns and \"AMT_CREDIT\" in train_fe.columns:\n",
    "    train_fe[\"GOODS_CREDIT_RATIO\"] = train_fe[\"AMT_GOODS_PRICE\"] / (\n",
    "        train_fe[\"AMT_CREDIT\"] + 1\n",
    "    )\n",
    "    test_fe[\"GOODS_CREDIT_RATIO\"] = test_fe[\"AMT_GOODS_PRICE\"] / (\n",
    "        test_fe[\"AMT_CREDIT\"] + 1\n",
    "    )\n",
    "    new_features_count += 1\n",
    "    print(\"  ‚úÖ GOODS_CREDIT_RATIO\")\n",
    "\n",
    "# Ratio Cr√©dit / Prix du bien (acompte implicite)\n",
    "if \"AMT_CREDIT\" in train_fe.columns and \"AMT_GOODS_PRICE\" in train_fe.columns:\n",
    "    train_fe[\"CREDIT_GOODS_RATIO\"] = train_fe[\"AMT_CREDIT\"] / (\n",
    "        train_fe[\"AMT_GOODS_PRICE\"] + 1\n",
    "    )\n",
    "    test_fe[\"CREDIT_GOODS_RATIO\"] = test_fe[\"AMT_CREDIT\"] / (\n",
    "        test_fe[\"AMT_GOODS_PRICE\"] + 1\n",
    "    )\n",
    "    new_features_count += 1\n",
    "    print(\"  ‚úÖ CREDIT_GOODS_RATIO\")\n",
    "\n",
    "# 2. FEATURES TEMPORELLES\n",
    "print(\"\\nüìÖ Cr√©ation des features temporelles...\")\n",
    "\n",
    "# √Çge en ann√©es\n",
    "if \"DAYS_BIRTH\" in train_fe.columns:\n",
    "    train_fe[\"AGE_YEARS\"] = -train_fe[\"DAYS_BIRTH\"] / 365\n",
    "    test_fe[\"AGE_YEARS\"] = -test_fe[\"DAYS_BIRTH\"] / 365\n",
    "    new_features_count += 1\n",
    "    print(\"  ‚úÖ AGE_YEARS\")\n",
    "\n",
    "# Anciennet√© emploi en ann√©es\n",
    "if \"DAYS_EMPLOYED\" in train_fe.columns:\n",
    "    # Remplacer les valeurs aberrantes (365243 = valeur par d√©faut pour ch√¥meurs)\n",
    "    train_fe[\"EMPLOYMENT_YEARS\"] = train_fe[\"DAYS_EMPLOYED\"].apply(\n",
    "        lambda x: -x / 365 if x != 365243 else 0\n",
    "    )\n",
    "    test_fe[\"EMPLOYMENT_YEARS\"] = test_fe[\"DAYS_EMPLOYED\"].apply(\n",
    "        lambda x: -x / 365 if x != 365243 else 0\n",
    "    )\n",
    "    new_features_count += 1\n",
    "    print(\"  ‚úÖ EMPLOYMENT_YEARS\")\n",
    "\n",
    "# 3. SCORES EXTERNES AGR√âG√âS\n",
    "print(\"\\nüìä Cr√©ation des features de scores...\")\n",
    "\n",
    "# Moyenne des scores externes\n",
    "ext_sources = [\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]\n",
    "if all(col in train_fe.columns for col in ext_sources):\n",
    "    train_fe[\"EXT_SOURCE_MEAN\"] = train_fe[ext_sources].mean(axis=1)\n",
    "    test_fe[\"EXT_SOURCE_MEAN\"] = test_fe[ext_sources].mean(axis=1)\n",
    "    new_features_count += 1\n",
    "    print(\"  ‚úÖ EXT_SOURCE_MEAN\")\n",
    "\n",
    "    # Produit des scores (interaction multiplicative)\n",
    "    train_fe[\"EXT_SOURCE_PROD\"] = (\n",
    "        train_fe[\"EXT_SOURCE_1\"] * train_fe[\"EXT_SOURCE_2\"] * train_fe[\"EXT_SOURCE_3\"]\n",
    "    )\n",
    "    test_fe[\"EXT_SOURCE_PROD\"] = (\n",
    "        test_fe[\"EXT_SOURCE_1\"] * test_fe[\"EXT_SOURCE_2\"] * test_fe[\"EXT_SOURCE_3\"]\n",
    "    )\n",
    "    new_features_count += 1\n",
    "    print(\"  ‚úÖ EXT_SOURCE_PROD\")\n",
    "\n",
    "# 4. FEATURES D√âMOGRAPHIQUES\n",
    "print(\"\\nüë• Cr√©ation des features d√©mographiques...\")\n",
    "\n",
    "# Ratio revenu / nombre de personnes du foyer\n",
    "if \"AMT_INCOME_TOTAL\" in train_fe.columns and \"CNT_FAM_MEMBERS\" in train_fe.columns:\n",
    "    train_fe[\"INCOME_PER_PERSON\"] = train_fe[\"AMT_INCOME_TOTAL\"] / (\n",
    "        train_fe[\"CNT_FAM_MEMBERS\"] + 1\n",
    "    )\n",
    "    test_fe[\"INCOME_PER_PERSON\"] = test_fe[\"AMT_INCOME_TOTAL\"] / (\n",
    "        test_fe[\"CNT_FAM_MEMBERS\"] + 1\n",
    "    )\n",
    "    new_features_count += 1\n",
    "    print(\"  ‚úÖ INCOME_PER_PERSON\")\n",
    "\n",
    "# Ratio enfants / famille\n",
    "if \"CNT_CHILDREN\" in train_fe.columns and \"CNT_FAM_MEMBERS\" in train_fe.columns:\n",
    "    train_fe[\"CHILDREN_RATIO\"] = train_fe[\"CNT_CHILDREN\"] / (\n",
    "        train_fe[\"CNT_FAM_MEMBERS\"] + 1\n",
    "    )\n",
    "    test_fe[\"CHILDREN_RATIO\"] = test_fe[\"CNT_CHILDREN\"] / (\n",
    "        test_fe[\"CNT_FAM_MEMBERS\"] + 1\n",
    "    )\n",
    "    new_features_count += 1\n",
    "    print(\"  ‚úÖ CHILDREN_RATIO\")\n",
    "\n",
    "# 5. FEATURES BUREAU (si pr√©sentes)\n",
    "print(\"\\nüè¶ Cr√©ation des features bureau...\")\n",
    "\n",
    "# Ratio dette bureau / revenu\n",
    "if (\n",
    "    \"BUREAU_AMT_CREDIT_SUM_DEBT_SUM\" in train_fe.columns\n",
    "    and \"AMT_INCOME_TOTAL\" in train_fe.columns\n",
    "):\n",
    "    train_fe[\"BUREAU_DEBT_INCOME_RATIO\"] = train_fe[\n",
    "        \"BUREAU_AMT_CREDIT_SUM_DEBT_SUM\"\n",
    "    ] / (train_fe[\"AMT_INCOME_TOTAL\"] + 1)\n",
    "    test_fe[\"BUREAU_DEBT_INCOME_RATIO\"] = test_fe[\"BUREAU_AMT_CREDIT_SUM_DEBT_SUM\"] / (\n",
    "        test_fe[\"AMT_INCOME_TOTAL\"] + 1\n",
    "    )\n",
    "    new_features_count += 1\n",
    "    print(\"  ‚úÖ BUREAU_DEBT_INCOME_RATIO\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total de nouvelles features cr√©√©es: {new_features_count}\")\n",
    "print(f\"   Shape finale: {train_fe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Gestion des Valeurs Infinies et Aberrantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Gestion des valeurs infinies et aberrantes...\n",
      "\n",
      "‚úÖ Aucune valeur infinie d√©tect√©e\n",
      "\n",
      "üìä V√©rification finale:\n",
      "   Train - NaN: 0\n",
      "   Train - Inf: 0\n",
      "   Test - NaN: 0\n",
      "   Test - Inf: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Gestion des valeurs infinies et aberrantes...\\n\")\n",
    "\n",
    "# Remplacer les valeurs infinies par NaN puis par 0\n",
    "train_fe = train_fe.replace([np.inf, -np.inf], np.nan)\n",
    "test_fe = test_fe.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Compter les NaN cr√©√©s\n",
    "nan_train = train_fe.isnull().sum().sum()\n",
    "nan_test = test_fe.isnull().sum().sum()\n",
    "\n",
    "if nan_train > 0 or nan_test > 0:\n",
    "    print(f\"‚ö†Ô∏è Valeurs infinies d√©tect√©es:\")\n",
    "    print(f\"   Train: {nan_train}\")\n",
    "    print(f\"   Test: {nan_test}\")\n",
    "\n",
    "    # Remplir les NaN cr√©√©s avec 0\n",
    "    train_fe = train_fe.fillna(0)\n",
    "    test_fe = test_fe.fillna(0)\n",
    "    print(f\"   ‚úÖ Remplac√©es par 0\")\n",
    "else:\n",
    "    print(\"‚úÖ Aucune valeur infinie d√©tect√©e\")\n",
    "\n",
    "# V√©rification finale\n",
    "print(f\"\\nüìä V√©rification finale:\")\n",
    "print(f\"   Train - NaN: {train_fe.isnull().sum().sum()}\")\n",
    "print(\n",
    "    f\"   Train - Inf: {np.isinf(train_fe.select_dtypes(include=[np.number])).sum().sum()}\"\n",
    ")\n",
    "print(f\"   Test - NaN: {test_fe.isnull().sum().sum()}\")\n",
    "print(\n",
    "    f\"   Test - Inf: {np.isinf(test_fe.select_dtypes(include=[np.number])).sum().sum()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Normalisation / Scaling\n",
    "\n",
    "**Important:** On scale uniquement les features num√©riques, pas TARGET ni SK_ID_CURR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Normalisation des features (StandardScaler)...\n",
      "\n",
      "‚úÖ Scaling appliqu√© sur 419 colonnes\n",
      "   Mean apr√®s scaling (train): 0.000000\n",
      "   Std apr√®s scaling (train): 1.000002\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Normalisation des features (StandardScaler)...\\n\")\n",
    "\n",
    "# Identifier les colonnes √† scaler (toutes sauf ID et TARGET)\n",
    "cols_to_scale = [col for col in train_fe.columns if col not in [\"SK_ID_CURR\", \"TARGET\"]]\n",
    "\n",
    "# Initialiser le scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit sur train, transform sur train et test\n",
    "train_scaled = train_fe.copy()\n",
    "test_scaled = test_fe.copy()\n",
    "\n",
    "train_scaled[cols_to_scale] = scaler.fit_transform(train_fe[cols_to_scale])\n",
    "test_scaled[cols_to_scale] = scaler.transform(test_fe[cols_to_scale])\n",
    "\n",
    "print(f\"‚úÖ Scaling appliqu√© sur {len(cols_to_scale)} colonnes\")\n",
    "print(f\"   Mean apr√®s scaling (train): {train_scaled[cols_to_scale].mean().mean():.6f}\")\n",
    "print(f\"   Std apr√®s scaling (train): {train_scaled[cols_to_scale].std().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. V√©rifications Finales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä V√âRIFICATIONS FINALES\n",
      "\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£ SHAPES\n",
      "   Train: (307511, 421)\n",
      "   Test: (48744, 421)\n",
      "\n",
      "2Ô∏è‚É£ VALEURS MANQUANTES\n",
      "   Train NaN: 0\n",
      "   Test NaN: 0\n",
      "\n",
      "3Ô∏è‚É£ VALEURS INFINIES\n",
      "   Train Inf: 0\n",
      "   Test Inf: 0\n",
      "\n",
      "4Ô∏è‚É£ COLONNES\n",
      "   Train: 421\n",
      "   Test: 421\n",
      "   ‚úÖ Colonnes align√©es\n",
      "\n",
      "5Ô∏è‚É£ DISTRIBUTION TARGET (inchang√©e)\n",
      "   {0: 282686, 1: 24825}\n",
      "   Taux de d√©faut: 8.07%\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä V√âRIFICATIONS FINALES\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Shapes\n",
    "print(f\"\\n1Ô∏è‚É£ SHAPES\")\n",
    "print(f\"   Train: {train_scaled.shape}\")\n",
    "print(f\"   Test: {test_scaled.shape}\")\n",
    "\n",
    "# 2. Valeurs manquantes\n",
    "print(f\"\\n2Ô∏è‚É£ VALEURS MANQUANTES\")\n",
    "print(f\"   Train NaN: {train_scaled.isnull().sum().sum()}\")\n",
    "print(f\"   Test NaN: {test_scaled.isnull().sum().sum()}\")\n",
    "\n",
    "# 3. Valeurs infinies\n",
    "numeric_train = train_scaled.select_dtypes(include=[np.number])\n",
    "numeric_test = test_scaled.select_dtypes(include=[np.number])\n",
    "print(f\"\\n3Ô∏è‚É£ VALEURS INFINIES\")\n",
    "print(f\"   Train Inf: {np.isinf(numeric_train).sum().sum()}\")\n",
    "print(f\"   Test Inf: {np.isinf(numeric_test).sum().sum()}\")\n",
    "\n",
    "# 4. Colonnes communes\n",
    "print(f\"\\n4Ô∏è‚É£ COLONNES\")\n",
    "print(f\"   Train: {len(train_scaled.columns)}\")\n",
    "print(f\"   Test: {len(test_scaled.columns)}\")\n",
    "diff_cols = set(train_scaled.columns) - set(test_scaled.columns)\n",
    "if diff_cols:\n",
    "    print(f\"   ‚ö†Ô∏è Diff√©rence: {diff_cols}\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Colonnes align√©es\")\n",
    "\n",
    "# 5. Distribution TARGET\n",
    "print(f\"\\n5Ô∏è‚É£ DISTRIBUTION TARGET (inchang√©e)\")\n",
    "if \"TARGET\" in train_scaled.columns:\n",
    "    print(f\"   {train_scaled['TARGET'].value_counts().to_dict()}\")\n",
    "    print(f\"   Taux de d√©faut: {train_scaled['TARGET'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Statistiques Descriptives Post-Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Statistiques de quelques features importantes (apr√®s scaling):\n",
      "\n",
      "         AMT_CREDIT  AMT_INCOME_TOTAL  CREDIT_INCOME_RATIO     AGE_YEARS  \\\n",
      "count  3.075110e+05      3.075110e+05         3.075110e+05  3.075110e+05   \n",
      "mean  -4.545000e-17     -1.229253e-17         1.626680e-17 -1.061039e-16   \n",
      "std    1.000002e+00      1.000002e+00         1.000002e+00  1.000002e+00   \n",
      "min   -1.376496e+00     -6.036870e-01        -1.469585e+00 -1.958761e+00   \n",
      "25%   -8.174760e-01     -2.374210e-01        -7.208551e-01 -8.304332e-01   \n",
      "50%   -2.124151e-01     -9.129414e-02        -2.574625e-01 -6.576450e-02   \n",
      "75%    5.208178e-01      1.421293e-01         4.470103e-01  8.352476e-01   \n",
      "max    8.574059e+00      4.927034e+02         3.003169e+01  2.106335e+00   \n",
      "\n",
      "       EXT_SOURCE_MEAN  BUREAU_DEBT_INCOME_RATIO  \n",
      "count     3.075110e+05              3.075110e+05  \n",
      "mean      9.068743e-16              1.330920e-17  \n",
      "std       1.000002e+00              1.000002e+00  \n",
      "min      -4.512323e+00             -2.461514e+00  \n",
      "25%      -6.465937e-01             -4.077968e-01  \n",
      "50%       9.306953e-02             -3.275525e-01  \n",
      "75%       7.049933e-01              5.748300e-02  \n",
      "max       3.162839e+00              2.182518e+02  \n"
     ]
    }
   ],
   "source": [
    "# Statistiques sur quelques features importantes\n",
    "important_features = [\n",
    "    \"AMT_CREDIT\",\n",
    "    \"AMT_INCOME_TOTAL\",\n",
    "    \"CREDIT_INCOME_RATIO\",\n",
    "    \"AGE_YEARS\",\n",
    "    \"EXT_SOURCE_MEAN\",\n",
    "    \"BUREAU_DEBT_INCOME_RATIO\",\n",
    "]\n",
    "\n",
    "# Filtrer les features qui existent\n",
    "existing_features = [f for f in important_features if f in train_scaled.columns]\n",
    "\n",
    "if existing_features:\n",
    "    print(\"üìä Statistiques de quelques features importantes (apr√®s scaling):\\n\")\n",
    "    print(train_scaled[existing_features].describe())\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Aucune des features importantes n'est pr√©sente dans le dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Nettoyage des Noms de Colonnes (Compatibilit√© LightGBM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Nettoyage des noms de colonnes...\n",
      "‚úÖ Noms de colonnes nettoy√©s\n",
      "   Exemple: ['SK_ID_CURR', 'TARGET', 'CNT_CHILDREN']\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Nettoyage des noms de colonnes...\")\n",
    "\n",
    "\n",
    "def clean_column_names(df):\n",
    "    \"\"\"\n",
    "    Nettoie les noms de colonnes pour la compatibilit√© avec LightGBM.\n",
    "    Remplace les caract√®res non-alphanum√©riques par des underscores.\n",
    "    \"\"\"\n",
    "    cleaned_columns = []\n",
    "    for col in df.columns:\n",
    "        # Remplacer tous les caract√®res non-alphanum√©riques par underscore\n",
    "        clean_col = \"\".join(c if c.isalnum() else \"_\" for c in col)\n",
    "        # Supprimer les underscores multiples cons√©cutifs\n",
    "        clean_col = \"_\".join(filter(None, clean_col.split(\"_\")))\n",
    "        cleaned_columns.append(clean_col)\n",
    "\n",
    "    return cleaned_columns\n",
    "\n",
    "\n",
    "# Appliquer le nettoyage\n",
    "train_scaled.columns = clean_column_names(train_scaled)\n",
    "test_scaled.columns = clean_column_names(test_scaled)\n",
    "\n",
    "print(f\"‚úÖ Noms de colonnes nettoy√©s\")\n",
    "print(f\"   Exemple: {list(train_scaled.columns[:3])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Sauvegarde des Datasets Preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Sauvegarde des datasets preprocessed...\n",
      "\n",
      "‚úÖ Datasets sauvegard√©s:\n",
      "   - train_preprocessed.csv: (307511, 421)\n",
      "   - test_preprocessed.csv: (48744, 421)\n",
      "   - scaler.pkl sauvegard√©\n",
      "\n",
      "üéâ Preprocessing termin√© avec succ√®s !\n"
     ]
    }
   ],
   "source": [
    "# Chemins de sauvegarde\n",
    "output_path = Path(\"../data\")\n",
    "\n",
    "print(\"üíæ Sauvegarde des datasets preprocessed...\\n\")\n",
    "\n",
    "# Sauvegarder les datasets\n",
    "train_scaled.to_csv(output_path / \"train_preprocessed.csv\", index=False)\n",
    "test_scaled.to_csv(output_path / \"test_preprocessed.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Datasets sauvegard√©s:\")\n",
    "print(f\"   - train_preprocessed.csv: {train_scaled.shape}\")\n",
    "print(f\"   - test_preprocessed.csv: {test_scaled.shape}\")\n",
    "\n",
    "# Sauvegarder aussi le scaler pour pouvoir l'utiliser en production\n",
    "import joblib\n",
    "\n",
    "scaler_path = output_path / \"scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"   - scaler.pkl sauvegard√©\")\n",
    "\n",
    "print(\"\\nüéâ Preprocessing termin√© avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìã R√âSUM√â D√âTAILL√â - Notebook 2 : Preprocessing & Feature Engineering\n",
    "\n",
    "## üéØ **OBJECTIF GLOBAL DU NOTEBOOK**\n",
    "\n",
    "Transformer les donn√©es **agr√©g√©es mais brutes** (avec NaN, variables cat√©gorielles, √©chelles diff√©rentes) en donn√©es **propres et optimis√©es** pour l'entra√Ænement de mod√®les de Machine Learning, tout en **cr√©ant de nouvelles features pertinentes** qui capturent mieux les patterns m√©tier.\n",
    "\n",
    "**Entr√©e :** `train_aggregated.csv` (307,511 √ó 305, avec 250 colonnes ayant des NaN)\n",
    "**Sortie :** `train_preprocessed.csv` (307,511 √ó ~260, 0 NaN, tout scal√©, +15 features cr√©√©es)\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **PARTIE 1 : CHARGEMENT & DIAGNOSTIC INITIAL**\n",
    "\n",
    "### **1.1 Chargement des Donn√©es Agr√©g√©es**\n",
    "\n",
    "**Fichiers Charg√©s :**\n",
    "\n",
    "```\n",
    "train_aggregated.csv : (307,511 √ó 305)\n",
    "test_aggregated.csv : (48,744 √ó 304)\n",
    "```\n",
    "\n",
    "**S√©paration Imm√©diate :**\n",
    "\n",
    "```python\n",
    "y_train = train['TARGET']  # Variable cible √† pr√©dire\n",
    "train_ids = train['SK_ID_CURR']  # Identifiants clients\n",
    "test_ids = test['SK_ID_CURR']\n",
    "```\n",
    "\n",
    "**Pourquoi S√©parer Imm√©diatement ?**\n",
    "\n",
    "- `TARGET` ne doit **jamais** √™tre transform√©e (scaling, encoding, etc.)\n",
    "- `SK_ID_CURR` est juste un identifiant, pas une feature pr√©dictive\n",
    "- On les garde de c√¥t√© et on les r√©int√®gre √† la fin\n",
    "\n",
    "### **1.2 Analyse Pr√©liminaire des NaN**\n",
    "\n",
    "**Fonction `analyze_missing()` :**\n",
    "\n",
    "Cette fonction classe les colonnes par % de NaN :\n",
    "\n",
    "| Cat√©gorie  | % NaN  | Nombre de Colonnes | Strat√©gie Pr√©vue                      |\n",
    "| ---------- | ------ | ------------------ | ------------------------------------- |\n",
    "| Tr√®s √©lev√© | >80%   | ~50 colonnes       | **Supprimer** (peu informatif)        |\n",
    "| √âlev√©      | 50-80% | ~80 colonnes       | **Imputer** avec strat√©gie sp√©cifique |\n",
    "| Mod√©r√©     | 30-50% | ~60 colonnes       | **Imputer** avec m√©diane/0            |\n",
    "| Faible     | <30%   | ~60 colonnes       | **Imputer** avec m√©diane              |\n",
    "\n",
    "**Insight Cl√© :**\n",
    "\n",
    "```\n",
    "250 colonnes sur 305 contiennent des NaN (82%)\n",
    "```\n",
    "\n",
    "**C'est Normal !** Rappel : les NaN viennent de l'absence d'historique (bureau, previous_app, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "## üèóÔ∏è **PARTIE 2 : STRAT√âGIE \"HAS_HISTORY\" - LA CL√â DU PREPROCESSING**\n",
    "\n",
    "### **2.1 Philosophie : L'Absence est Une Information**\n",
    "\n",
    "**Probl√®me √† R√©soudre :**\n",
    "\n",
    "Imagine deux clients :\n",
    "\n",
    "```\n",
    "Client A :\n",
    "- BUREAU_AMT_CREDIT_SUM_MEAN = NaN (apr√®s imputation ‚Üí 0)\n",
    "- Interpr√©tation : Aucun cr√©dit bureau\n",
    "\n",
    "Client B :\n",
    "- BUREAU_AMT_CREDIT_SUM_MEAN = 0‚Ç¨ (vraie moyenne)\n",
    "- Interpr√©tation : A des cr√©dits bureau, mais montant moyen = 0‚Ç¨\n",
    "```\n",
    "\n",
    "**Apr√®s imputation classique, A et B sont identiques ‚Üí PERTE D'INFORMATION !**\n",
    "\n",
    "### **2.2 Solution : Features \"Has_History\"**\n",
    "\n",
    "**Strat√©gie :**\n",
    "\n",
    "1. **AVANT** de remplir les NaN, on cr√©e des indicateurs binaires\n",
    "2. Ces indicateurs capturent l'**existence ou absence** d'historique\n",
    "3. **PUIS** on remplit les NaN\n",
    "\n",
    "**5 Features Cr√©√©es :**\n",
    "\n",
    "| Feature Cr√©√©e      | Colonne de R√©f√©rence               | Signification                              |\n",
    "| ------------------ | ---------------------------------- | ------------------------------------------ |\n",
    "| `HAS_BUREAU`       | `BUREAU_SK_ID_BUREAU_COUNT`        | 1 = a des cr√©dits bureau, 0 = aucun        |\n",
    "| `HAS_PREV_APP`     | `PREV_AMT_ANNUITY_MEAN`            | 1 = a des demandes pr√©c√©dentes, 0 = aucune |\n",
    "| `HAS_CREDIT_CARD`  | `CC_AMT_PAYMENT_CURRENT_MEAN_MEAN` | 1 = a eu une carte de cr√©dit, 0 = jamais   |\n",
    "| `HAS_POS_CASH`     | `POS_MONTHS_BALANCE_MIN_MEAN`      | 1 = a eu cr√©dit point de vente, 0 = jamais |\n",
    "| `HAS_INSTALLMENTS` | `INSTAL_PAYMENT_DIFF_MEAN_MEAN`    | 1 = a historique paiements, 0 = aucun      |\n",
    "\n",
    "**Exemple Concret :**\n",
    "\n",
    "```python\n",
    "# Avant imputation\n",
    "train['BUREAU_AMT_CREDIT_SUM_MEAN'] = [10000, NaN, 5000]\n",
    "\n",
    "# On cr√©e HAS_BUREAU\n",
    "train['HAS_BUREAU'] = [1, 0, 1]  # 1 si pas NaN, 0 si NaN\n",
    "\n",
    "# Puis imputation\n",
    "train['BUREAU_AMT_CREDIT_SUM_MEAN'] = [10000, 0, 5000]\n",
    "\n",
    "# Maintenant on peut distinguer :\n",
    "# Ligne 2 : HAS_BUREAU=0, AMT=0 ‚Üí vraiment AUCUN cr√©dit bureau\n",
    "# Ligne 3 : HAS_BUREAU=1, AMT=5000 ‚Üí A des cr√©dits, moyenne 5000‚Ç¨\n",
    "```\n",
    "\n",
    "### **2.3 Impact M√©tier**\n",
    "\n",
    "**HAS_BUREAU = 0** peut indiquer :\n",
    "\n",
    "- Nouveau dans le syst√®me bancaire ‚Üí **Plus risqu√©** (pas d'historique de remboursement)\n",
    "- Tr√®s jeune ‚Üí **Plus risqu√©**\n",
    "- Jamais emprunt√© ‚Üí **Plus prudent** ou **Plus risqu√©** selon contexte\n",
    "\n",
    "**HAS_BUREAU = 1** indique :\n",
    "\n",
    "- Exp√©rience bancaire ‚Üí **Moins risqu√©** si bon historique\n",
    "- **Plus risqu√©** si mauvais historique (captur√© par d'autres features)\n",
    "\n",
    "**R√©sultat Attendu :**\n",
    "\n",
    "```\n",
    "HAS_BUREAU: 99.4% des clients ont un historique bureau\n",
    "HAS_PREV_APP: 60.2% ont des demandes pr√©c√©dentes\n",
    "HAS_CREDIT_CARD: 17.2% ont eu une carte\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üóëÔ∏è **PARTIE 3 : SUPPRESSION DES COLONNES PEU INFORMATIVES**\n",
    "\n",
    "### **3.1 Strat√©gie de Seuil : 80%**\n",
    "\n",
    "**R√®gle de D√©cision :**\n",
    "\n",
    "```\n",
    "SI colonne a >80% de NaN\n",
    "ALORS supprimer\n",
    "SINON garder\n",
    "```\n",
    "\n",
    "**Pourquoi 80% ?**\n",
    "\n",
    "**L'analogie du sondage :**\n",
    "\n",
    "- Tu fais un sondage sur 100 personnes\n",
    "- Une question n'a que 20 r√©ponses (80% ne r√©pondent pas)\n",
    "- Cette question apporte **tr√®s peu** d'information\n",
    "\n",
    "**En ML, c'est pareil :**\n",
    "\n",
    "- Une feature avec 80% de NaN n'a que 20% de valeurs r√©elles\n",
    "- Trop peu pour apprendre un pattern robuste\n",
    "- Risque d'**overfitting** sur ces 20%\n",
    "\n",
    "### **3.2 Colonnes Prot√©g√©es**\n",
    "\n",
    "```python\n",
    "if col in ['SK_ID_CURR', 'TARGET']:\n",
    "    continue  # Ne JAMAIS supprimer ces colonnes !\n",
    "```\n",
    "\n",
    "**Pourquoi ?**\n",
    "\n",
    "- `SK_ID_CURR` : identifiant n√©cessaire pour la soumission Kaggle\n",
    "- `TARGET` : la variable √† pr√©dire !\n",
    "\n",
    "### **3.3 R√©sultats Attendus**\n",
    "\n",
    "```\n",
    "Avant: 305 colonnes\n",
    "Colonnes √† supprimer: ~45-50 colonnes\n",
    "Apr√®s: ~255-260 colonnes\n",
    "\n",
    "Exemples de colonnes supprim√©es:\n",
    "- CC_AMT_PAYMENT_CURRENT_MEAN: 82.82% NaN\n",
    "- CC_AMT_DRAWINGS_ATM_CURRENT: 82.79% NaN\n",
    "- COMMONAREA_MEDI: 69.87% NaN (gard√©e car <80%)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üî¢ **PARTIE 4 : S√âPARATION DES TYPES DE COLONNES**\n",
    "\n",
    "### **4.1 Classification des Colonnes**\n",
    "\n",
    "**4 Cat√©gories :**\n",
    "\n",
    "| Type              | Exemples                            | Nombre | Traitement                 |\n",
    "| ----------------- | ----------------------------------- | ------ | -------------------------- |\n",
    "| **ID**            | `SK_ID_CURR`                        | 1      | Aucun (juste conservation) |\n",
    "| **Target**        | `TARGET`                            | 1      | Aucun (√† pr√©dire)          |\n",
    "| **Cat√©gorielles** | `NAME_CONTRACT_TYPE`, `CODE_GENDER` | ~15    | One-Hot Encoding           |\n",
    "| **Num√©riques**    | `AMT_CREDIT`, `DAYS_BIRTH`          | ~240   | Imputation + Scaling       |\n",
    "\n",
    "### **4.2 Identification Automatique**\n",
    "\n",
    "```python\n",
    "# Cat√©gorielles : type 'object' (texte)\n",
    "categorical_cols = train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Num√©riques : types num√©riques\n",
    "numeric_cols = train.select_dtypes(include=[np.number]).columns\n",
    "```\n",
    "\n",
    "**Pourquoi Automatique ?**\n",
    "\n",
    "Apr√®s l'agr√©gation du Notebook 1, on ne sait pas exactement quelles colonnes cat√©gorielles restent. Cette m√©thode s'adapte automatiquement.\n",
    "\n",
    "### **4.3 Analyse des Cat√©gorielles**\n",
    "\n",
    "Pour chaque colonne cat√©gorielle, on affiche :\n",
    "\n",
    "```\n",
    "NAME_CONTRACT_TYPE: 2 valeurs uniques\n",
    "CODE_GENDER: 3 valeurs uniques\n",
    "FLAG_OWN_CAR: 2 valeurs uniques\n",
    "```\n",
    "\n",
    "**Pourquoi Important ?**\n",
    "\n",
    "Si une colonne a **trop** de valeurs uniques (>50), le One-Hot Encoding cr√©era trop de colonnes ‚Üí on pourrait envisager du Label Encoding ou Target Encoding √† la place.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ **PARTIE 5 : ENCODAGE DES VARIABLES CAT√âGORIELLES**\n",
    "\n",
    "### **5.1 Technique : One-Hot Encoding**\n",
    "\n",
    "**Transformation :**\n",
    "\n",
    "```\n",
    "Avant (cat√©gorielle):\n",
    "NAME_CONTRACT_TYPE\n",
    "['Cash loans', 'Revolving loans', 'Cash loans', 'Cash loans']\n",
    "\n",
    "Apr√®s (num√©riques):\n",
    "NAME_CONTRACT_TYPE_Cash_loans | NAME_CONTRACT_TYPE_Revolving_loans\n",
    "[1, 0, 1, 1]                  | [0, 1, 0, 0]\n",
    "```\n",
    "\n",
    "### **5.2 Param√®tre Crucial : `drop_first=True`**\n",
    "\n",
    "**Sans `drop_first` :**\n",
    "\n",
    "```\n",
    "Cash_loans | Revolving_loans\n",
    "1          | 0\n",
    "0          | 1\n",
    "```\n",
    "\n",
    "**Probl√®me :** Si `Cash_loans=0`, alors **forc√©ment** `Revolving_loans=1` ‚Üí **multicolin√©arit√© parfaite** !\n",
    "\n",
    "**Avec `drop_first=True` :**\n",
    "\n",
    "```\n",
    "Cash_loans\n",
    "1  ‚Üí Cash loans\n",
    "0  ‚Üí Revolving loans (implicite)\n",
    "```\n",
    "\n",
    "Une seule colonne suffit pour encoder 2 valeurs !\n",
    "\n",
    "### **5.3 Alignement Train-Test**\n",
    "\n",
    "**Probl√®me Potentiel :**\n",
    "\n",
    "```\n",
    "Train :\n",
    "CODE_GENDER = ['M', 'F', 'XNA']\n",
    "‚Üí CODE_GENDER_F, CODE_GENDER_XNA\n",
    "\n",
    "Test :\n",
    "CODE_GENDER = ['M', 'F']  # Pas de 'XNA' !\n",
    "‚Üí CODE_GENDER_F  # Manque CODE_GENDER_XNA !\n",
    "```\n",
    "\n",
    "**Solution : `align()` :**\n",
    "\n",
    "```python\n",
    "train_encoded, test_encoded = train_encoded.align(\n",
    "    test_encoded,\n",
    "    join='left',  # Garder toutes les colonnes de train\n",
    "    axis=1,       # Sur les colonnes\n",
    "    fill_value=0  # Remplir les colonnes manquantes avec 0\n",
    ")\n",
    "```\n",
    "\n",
    "**R√©sultat :**\n",
    "Train et Test ont **exactement** les m√™mes colonnes, dans le m√™me ordre.\n",
    "\n",
    "### **5.4 Impact sur le Nombre de Colonnes**\n",
    "\n",
    "```\n",
    "Avant encodage: ~255 colonnes\n",
    "Colonnes cat√©gorielles: 15\n",
    "Valeurs uniques totales: ~30\n",
    "\n",
    "Apr√®s encodage:\n",
    "Colonnes supprim√©es: 15 (les cat√©gorielles originales)\n",
    "Colonnes ajout√©es: ~25 (one-hot encod√©es, avec drop_first)\n",
    "\n",
    "Total: ~255 - 15 + 25 = ~265 colonnes\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîß **PARTIE 6 : IMPUTATION STRAT√âGIQUE DES VALEURS MANQUANTES**\n",
    "\n",
    "### **6.1 Philosophie G√©n√©rale**\n",
    "\n",
    "**Principe :** Toutes les NaN ne se valent pas ‚Üí on adapte la strat√©gie d'imputation au **type s√©mantique** de la colonne.\n",
    "\n",
    "### **6.2 Les 5 Strat√©gies d'Imputation**\n",
    "\n",
    "#### **Strat√©gie 1 : Colonnes de Montants ‚Üí 0**\n",
    "\n",
    "**Colonnes Concern√©es :**\n",
    "\n",
    "```\n",
    "Contiennent : 'AMT', 'SUM', 'CREDIT', 'PAYMENT', 'BALANCE', 'GOODS', 'PRICE'\n",
    "Exemples : AMT_CREDIT, BUREAU_AMT_CREDIT_SUM_MEAN, CC_AMT_PAYMENT_CURRENT\n",
    "```\n",
    "\n",
    "**Logique :**\n",
    "\n",
    "```\n",
    "NaN dans un montant = pas de cr√©dit/paiement = 0‚Ç¨\n",
    "\n",
    "Exemple :\n",
    "BUREAU_AMT_CREDIT_SUM_MEAN = NaN\n",
    "‚Üí Le client n'a AUCUN cr√©dit bureau\n",
    "‚Üí Montant total = 0‚Ç¨ (pas 10,000‚Ç¨ de moyenne par exemple)\n",
    "```\n",
    "\n",
    "**Code :**\n",
    "\n",
    "```python\n",
    "train[amount_cols] = train[amount_cols].fillna(0)\n",
    "```\n",
    "\n",
    "#### **Strat√©gie 2 : Colonnes de Comptage ‚Üí 0**\n",
    "\n",
    "**Colonnes Concern√©es :**\n",
    "\n",
    "```\n",
    "Contiennent : 'COUNT', 'CNT', 'NUMBER', 'NUM'\n",
    "Exemples : BUREAU_SK_ID_BUREAU_COUNT, CNT_CHILDREN\n",
    "```\n",
    "\n",
    "**Logique :**\n",
    "\n",
    "```\n",
    "NaN dans un comptage = 0 occurrence\n",
    "\n",
    "Exemple :\n",
    "BUREAU_SK_ID_BUREAU_COUNT = NaN\n",
    "‚Üí Le client a 0 cr√©dit bureau (pas 5 cr√©dits)\n",
    "```\n",
    "\n",
    "#### **Strat√©gie 3 : Colonnes de Dates ‚Üí -999**\n",
    "\n",
    "**Colonnes Concern√©es :**\n",
    "\n",
    "```\n",
    "Contiennent : 'DAYS'\n",
    "Exemples : DAYS_BIRTH, DAYS_EMPLOYED, BUREAU_DAYS_CREDIT_MIN\n",
    "```\n",
    "\n",
    "**Logique :**\n",
    "\n",
    "```\n",
    "NaN dans une date = information non disponible\n",
    "‚Üí Valeur sentinelle reconnaissable : -999\n",
    "\n",
    "Pourquoi pas 0 ?\n",
    "0 pourrait signifier \"aujourd'hui\", ce qui a un sens !\n",
    "-999 est clairement une valeur \"sp√©ciale\"\n",
    "```\n",
    "\n",
    "**Avantages :**\n",
    "\n",
    "- Les mod√®les tree-based (Random Forest, XGBoost) peuvent cr√©er des splits sur -999\n",
    "- Les mod√®les lin√©aires voient -999 comme \"tr√®s ancien\" ‚Üí peut capturer le pattern\n",
    "\n",
    "#### **Strat√©gie 4 : Colonnes de Moyennes/Ratios ‚Üí M√©diane**\n",
    "\n",
    "**Colonnes Concern√©es :**\n",
    "\n",
    "```\n",
    "Contiennent : 'MEAN', 'AVG', 'MEDIAN', 'MEDI', 'MODE'\n",
    "Exemples : PREV_AMT_ANNUITY_MEAN, EXT_SOURCE_2\n",
    "```\n",
    "\n",
    "**Logique :**\n",
    "\n",
    "```\n",
    "NaN dans une moyenne = valeur inconnue\n",
    "‚Üí On impute avec la m√©diane de la distribution\n",
    "\n",
    "Pourquoi m√©diane et pas moyenne ?\n",
    "La m√©diane est ROBUSTE AUX OUTLIERS\n",
    "```\n",
    "\n",
    "**Exemple Concret :**\n",
    "\n",
    "```\n",
    "Distribution de EXT_SOURCE_2:\n",
    "[0.1, 0.2, 0.3, 0.4, 0.5, 0.9, 0.9, 0.9, NaN, NaN]\n",
    "\n",
    "Moyenne = 0.47\n",
    "M√©diane = 0.45\n",
    "\n",
    "Si un client a NaN, on remplit avec 0.45\n",
    "```\n",
    "\n",
    "**Pourquoi la M√©diane ?**\n",
    "\n",
    "```\n",
    "Revenus annuels (en K‚Ç¨):\n",
    "[20, 25, 30, 35, 40, 500]  ‚Üê 500 est un outlier (CEO)\n",
    "\n",
    "Moyenne = 108.3K‚Ç¨ (biais√©e par l'outlier !)\n",
    "M√©diane = 32.5K‚Ç¨ (robuste, repr√©sente le \"client typique\")\n",
    "```\n",
    "\n",
    "#### **Strat√©gie 5 : Autres Colonnes ‚Üí M√©diane**\n",
    "\n",
    "**Colonnes Concern√©es :**\n",
    "Tout ce qui n'entre pas dans les 4 cat√©gories pr√©c√©dentes.\n",
    "\n",
    "**Logique :**\n",
    "Strat√©gie par d√©faut conservatrice.\n",
    "\n",
    "### **6.3 Ordre d'Application**\n",
    "\n",
    "**Tr√®s Important : L'ordre compte !**\n",
    "\n",
    "```python\n",
    "# 1. Montants ‚Üí 0\n",
    "# 2. Comptages ‚Üí 0  (√©viter doublons avec montants)\n",
    "# 3. Dates ‚Üí -999\n",
    "# 4. Moyennes ‚Üí m√©diane  (√©viter doublons avec montants/comptages/dates)\n",
    "# 5. Autres ‚Üí m√©diane  (tout le reste)\n",
    "```\n",
    "\n",
    "**Pourquoi ?**\n",
    "\n",
    "Une colonne comme `BUREAU_AMT_CREDIT_SUM_MEAN` contient √† la fois \"AMT\" et \"MEAN\".\n",
    "\n",
    "**Sans ordre strict :**\n",
    "\n",
    "```\n",
    "1. Cat√©gorie AMT ‚Üí rempli avec 0\n",
    "2. Cat√©gorie MEAN ‚Üí rempli avec m√©diane  ‚Üê CONFLIT !\n",
    "```\n",
    "\n",
    "**Avec ordre strict :**\n",
    "\n",
    "```\n",
    "1. On cat√©gorise d'abord par AMT ‚Üí rempli avec 0\n",
    "2. MEAN ne traite que les colonnes non d√©j√† trait√©es\n",
    "```\n",
    "\n",
    "### **6.4 V√©rification Post-Imputation**\n",
    "\n",
    "```python\n",
    "print(f\"Train - NaN restants: {train.isnull().sum().sum()}\")\n",
    "print(f\"Test - NaN restants: {test.isnull().sum().sum()}\")\n",
    "```\n",
    "\n",
    "**R√©sultat Attendu : 0 NaN partout !**\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ **PARTIE 7 : FEATURE ENGINEERING AVANC√â**\n",
    "\n",
    "### **7.1 Philosophie : Aider le Mod√®le √† Voir les Patterns**\n",
    "\n",
    "**Probl√®me :**\n",
    "\n",
    "Les mod√®les ML (surtout lin√©aires) ont du mal √† capturer :\n",
    "\n",
    "- **Relations non-lin√©aires** (ratios, produits)\n",
    "- **Interactions complexes** (effet combin√© de 2+ features)\n",
    "- **Patterns m√©tier** (r√®gles du domaine)\n",
    "\n",
    "**Solution :**\n",
    "\n",
    "On cr√©e **explicitement** des features qui capturent ces patterns.\n",
    "\n",
    "### **7.2 Cat√©gorie 1 : Ratios Financiers (4 features)**\n",
    "\n",
    "#### **Feature 1 : `CREDIT_INCOME_RATIO`**\n",
    "\n",
    "**Formule :**\n",
    "\n",
    "```python\n",
    "CREDIT_INCOME_RATIO = AMT_CREDIT / (AMT_INCOME_TOTAL + 1)\n",
    "```\n",
    "\n",
    "**Signification M√©tier :**\n",
    "\n",
    "```\n",
    "Ratio < 3 : Cr√©dit raisonnable (ex: 3 ans de salaire pour une voiture)\n",
    "Ratio 3-5 : Cr√©dit important (ex: 5 ans pour une maison)\n",
    "Ratio > 5 : Tr√®s endett√© ! (ex: 7 ans de salaire)\n",
    "```\n",
    "\n",
    "**Exemple :**\n",
    "\n",
    "```\n",
    "Client A: Cr√©dit 100K, Revenu 20K ‚Üí ratio = 5\n",
    "Client B: Cr√©dit 50K, Revenu 100K ‚Üí ratio = 0.5\n",
    "\n",
    "Sans cette feature, le mod√®le voit juste des nombres.\n",
    "Avec, il voit clairement que A est 10x plus endett√© relativement !\n",
    "```\n",
    "\n",
    "**Pourquoi \"+1\" au d√©nominateur ?**\n",
    "\n",
    "Pour √©viter la division par 0 si `AMT_INCOME_TOTAL = 0` (ce qui devrait √™tre rare mais possible apr√®s imputation).\n",
    "\n",
    "#### **Feature 2 : `ANNUITY_INCOME_RATIO`**\n",
    "\n",
    "**Formule :**\n",
    "\n",
    "```python\n",
    "ANNUITY_INCOME_RATIO = AMT_ANNUITY / (AMT_INCOME_TOTAL + 1)\n",
    "```\n",
    "\n",
    "**Signification M√©tier :**\n",
    "\n",
    "```\n",
    "Ratio < 0.2 : Mensualit√© confortable (20% du revenu)\n",
    "Ratio 0.2-0.3 : Mensualit√© √©lev√©e (20-30% du revenu)\n",
    "Ratio > 0.3 : Mensualit√© tr√®s √©lev√©e (>30% du revenu) ‚Üí risque !\n",
    "```\n",
    "\n",
    "**R√®gle Bancaire Classique :**\n",
    "\n",
    "La plupart des banques refusent si le ratio d√©passe 33% (r√®gle du \"tiers\").\n",
    "\n",
    "#### **Feature 3 : `GOODS_CREDIT_RATIO`**\n",
    "\n",
    "**Formule :**\n",
    "\n",
    "```python\n",
    "GOODS_CREDIT_RATIO = AMT_GOODS_PRICE / (AMT_CREDIT + 1)\n",
    "```\n",
    "\n",
    "**Signification M√©tier :**\n",
    "\n",
    "```\n",
    "Ratio ‚âà 1 : Cr√©dit = Prix du bien (pas d'acompte)\n",
    "Ratio < 1 : Cr√©dit < Prix (acompte important) ‚Üí bon signe !\n",
    "Ratio > 1 : Prix > Cr√©dit (impossible normalement)\n",
    "```\n",
    "\n",
    "**Exemple :**\n",
    "\n",
    "```\n",
    "Bien √† 50K‚Ç¨, Cr√©dit de 40K‚Ç¨\n",
    "‚Üí Ratio = 50/40 = 1.25\n",
    "‚Üí Acompte de 10K‚Ç¨ (20%) ‚Üí client s√©rieux !\n",
    "```\n",
    "\n",
    "#### **Feature 4 : `CREDIT_GOODS_RATIO`**\n",
    "\n",
    "**Formule :**\n",
    "\n",
    "```python\n",
    "CREDIT_GOODS_RATIO = AMT_CREDIT / (AMT_GOODS_PRICE + 1)\n",
    "```\n",
    "\n",
    "**Signification M√©tier :**\n",
    "\n",
    "```\n",
    "Ratio ‚âà 1 : Cr√©dit = Prix (normal)\n",
    "Ratio > 1 : Cr√©dit > Prix ‚Üí le client finance PLUS que le bien !\n",
    "           ‚Üí Peut inclure frais, assurances, ou RED FLAG\n",
    "```\n",
    "\n",
    "### **7.3 Cat√©gorie 2 : Features Temporelles (2 features)**\n",
    "\n",
    "#### **Feature 5 : `AGE_YEARS`**\n",
    "\n",
    "**Formule :**\n",
    "\n",
    "```python\n",
    "AGE_YEARS = -DAYS_BIRTH / 365\n",
    "```\n",
    "\n",
    "**Pourquoi ?**\n",
    "\n",
    "Les jours sont contre-intuitifs :\n",
    "\n",
    "```\n",
    "DAYS_BIRTH = -18250 ‚Üí √¢ge ???\n",
    "AGE_YEARS = 50 ‚Üí clair !\n",
    "```\n",
    "\n",
    "**Pattern Attendu :**\n",
    "\n",
    "```\n",
    "√Çge 18-25 : Jeunes, plus risqu√©s (peu d'historique)\n",
    "√Çge 25-40 : Moins risqu√©s (stabilit√©)\n",
    "√Çge 40-60 : Tr√®s fiables (carri√®re √©tablie)\n",
    "√Çge >60 : Risque mod√©r√© (retraite, revenu fixe)\n",
    "```\n",
    "\n",
    "#### **Feature 6 : `EMPLOYMENT_YEARS`**\n",
    "\n",
    "**Formule :**\n",
    "\n",
    "```python\n",
    "EMPLOYMENT_YEARS = -DAYS_EMPLOYED / 365 if DAYS_EMPLOYED != 365243 else 0\n",
    "```\n",
    "\n",
    "**Gestion Sp√©ciale : 365243**\n",
    "\n",
    "```\n",
    "DAYS_EMPLOYED = 365243 est une valeur PAR D√âFAUT\n",
    "‚Üí Signifie \"ch√¥meur\" ou \"pas d'emploi d√©clar√©\"\n",
    "‚Üí On transforme en 0 ans d'emploi\n",
    "```\n",
    "\n",
    "**Pattern Attendu :**\n",
    "\n",
    "```\n",
    "0 ans (ch√¥meur) : Tr√®s risqu√©\n",
    "<2 ans : Risqu√© (emploi instable)\n",
    "2-10 ans : Stable, bon signe\n",
    ">10 ans : Tr√®s stable, excellent signe\n",
    "```\n",
    "\n",
    "### **7.4 Cat√©gorie 3 : Scores Externes Agr√©g√©s (2 features)**\n",
    "\n",
    "#### **Feature 7 : `EXT_SOURCE_MEAN`**\n",
    "\n",
    "**Formule :**\n",
    "\n",
    "```python\n",
    "EXT_SOURCE_MEAN = (EXT_SOURCE_1 + EXT_SOURCE_2 + EXT_SOURCE_3) / 3\n",
    "```\n",
    "\n",
    "**Pourquoi ?**\n",
    "\n",
    "Les 3 scores externes sont **les features les plus pr√©dictives** du dataset !\n",
    "\n",
    "En cr√©ant leur moyenne, on capture un \"score global\" robuste.\n",
    "\n",
    "#### **Feature 8 : `EXT_SOURCE_PROD`**\n",
    "\n",
    "**Formule :**\n",
    "\n",
    "```python\n",
    "EXT_SOURCE_PROD = EXT_SOURCE_1 √ó EXT_SOURCE_2 √ó EXT_SOURCE_3\n",
    "```\n",
    "\n",
    "**Pourquoi le Produit ?**\n",
    "\n",
    "**Interaction Multiplicative :**\n",
    "\n",
    "```\n",
    "Client A: [0.8, 0.8, 0.8]\n",
    "Moyenne = 0.8\n",
    "Produit = 0.512\n",
    "\n",
    "Client B: [0.9, 0.9, 0.5]  ‚Üê Un score faible !\n",
    "Moyenne = 0.77 (presque pareil)\n",
    "Produit = 0.405 (beaucoup plus faible !)\n",
    "```\n",
    "\n",
    "Le produit **p√©nalise** les clients avec UN score faible, m√™me si les autres sont bons.\n",
    "\n",
    "### **7.5 Cat√©gorie 4 : Features D√©mographiques (2 features)**\n",
    "\n",
    "#### **Feature 9 : `INCOME_PER_PERSON`**\n",
    "\n",
    "**Formule :**\n",
    "\n",
    "```python\n",
    "INCOME_PER_PERSON = AMT_INCOME_TOTAL / (CNT_FAM_MEMBERS + 1)\n",
    "```\n",
    "\n",
    "**Signification M√©tier :**\n",
    "\n",
    "```\n",
    "Famille de 4, Revenu 40K ‚Üí 10K/personne ‚Üí serr√©\n",
    "C√©libataire, Revenu 40K ‚Üí 40K/personne ‚Üí confortable\n",
    "```\n",
    "\n",
    "**Capture le niveau de vie r√©el, pas juste le revenu brut.**\n",
    "\n",
    "#### **Feature 10 : `CHILDREN_RATIO`**\n",
    "\n",
    "**Formule :**\n",
    "\n",
    "```python\n",
    "CHILDREN_RATIO = CNT_CHILDREN / (CNT_FAM_MEMBERS + 1)\n",
    "```\n",
    "\n",
    "**Signification M√©tier :**\n",
    "\n",
    "```\n",
    "Ratio = 0 : Pas d'enfants ‚Üí moins de charges\n",
    "Ratio = 0.5 : Moiti√© enfants ‚Üí charges mod√©r√©es\n",
    "Ratio = 0.8 : Beaucoup d'enfants ‚Üí charges √©lev√©es\n",
    "```\n",
    "\n",
    "### **7.6 Cat√©gorie 5 : Features Bureau (1 feature)**\n",
    "\n",
    "#### **Feature 11 : `BUREAU_DEBT_INCOME_RATIO`**\n",
    "\n",
    "**Formule :**\n",
    "\n",
    "```python\n",
    "BUREAU_DEBT_INCOME_RATIO = BUREAU_AMT_CREDIT_SUM_DEBT_SUM / (AMT_INCOME_TOTAL + 1)\n",
    "```\n",
    "\n",
    "**Signification M√©tier :**\n",
    "\n",
    "```\n",
    "Ratio < 1 : Dette < 1 an de salaire ‚Üí g√©rable\n",
    "Ratio 1-3 : Dette mod√©r√©e\n",
    "Ratio > 3 : Tr√®s endett√© dans d'autres banques ‚Üí RISQUE !\n",
    "```\n",
    "\n",
    "### **7.7 R√©sum√© Feature Engineering**\n",
    "\n",
    "**Total : 10-15 Nouvelles Features**\n",
    "\n",
    "| Type              | Nombre | Exemples                                  |\n",
    "| ----------------- | ------ | ----------------------------------------- |\n",
    "| Ratios financiers | 4      | CREDIT_INCOME_RATIO, ANNUITY_INCOME_RATIO |\n",
    "| Temporelles       | 2      | AGE_YEARS, EMPLOYMENT_YEARS               |\n",
    "| Scores agr√©g√©s    | 2      | EXT_SOURCE_MEAN, EXT_SOURCE_PROD          |\n",
    "| D√©mographiques    | 2      | INCOME_PER_PERSON, CHILDREN_RATIO         |\n",
    "| Bureau            | 1      | BUREAU_DEBT_INCOME_RATIO                  |\n",
    "\n",
    "**Impact Attendu :**\n",
    "\n",
    "Ces features capturent des **patterns m√©tier** que le mod√®le aurait du mal √† d√©couvrir seul ‚Üí am√©lioration des performances !\n",
    "\n",
    "---\n",
    "\n",
    "## üîí **PARTIE 8 : GESTION DES VALEURS INFINIES**\n",
    "\n",
    "### **8.1 Origine des Valeurs Infinies**\n",
    "\n",
    "**Probl√®me :**\n",
    "\n",
    "M√™me avec \"+1\" dans les d√©nominateurs, des valeurs infinies peuvent appara√Ætre :\n",
    "\n",
    "```python\n",
    "# Si AMT_INCOME_TOTAL = -1 apr√®s imputation (rare mais possible)\n",
    "ratio = AMT_CREDIT / (AMT_INCOME_TOTAL + 1)\n",
    "ratio = 10000 / 0 = inf !\n",
    "```\n",
    "\n",
    "### **8.2 Strat√©gie de Correction**\n",
    "\n",
    "**√âtape 1 : Remplacer inf par NaN**\n",
    "\n",
    "```python\n",
    "train = train.replace([np.inf, -np.inf], np.nan)\n",
    "```\n",
    "\n",
    "**√âtape 2 : Remplir les NaN cr√©√©s avec 0**\n",
    "\n",
    "```python\n",
    "train = train.fillna(0)\n",
    "```\n",
    "\n",
    "**Pourquoi 0 ?**\n",
    "\n",
    "Une valeur infinie dans un ratio indique g√©n√©ralement un probl√®me de donn√©es ‚Üí on met une valeur neutre.\n",
    "\n",
    "### **8.3 V√©rification**\n",
    "\n",
    "```python\n",
    "np.isinf(train.select_dtypes(include=[np.number])).sum().sum()\n",
    "# R√©sultat attendu : 0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìè **PARTIE 9 : NORMALISATION (STANDARDSCALER)**\n",
    "\n",
    "### **9.1 Pourquoi Normaliser ?**\n",
    "\n",
    "**Probl√®me : √âchelles Tr√®s Diff√©rentes**\n",
    "\n",
    "```\n",
    "AMT_CREDIT : [10,000 - 500,000]  ‚Üí √©chelle ~100,000\n",
    "AGE_YEARS : [20 - 70]            ‚Üí √©chelle ~50\n",
    "EXT_SOURCE_2 : [0 - 1]           ‚Üí √©chelle 1\n",
    "```\n",
    "\n",
    "**Impact sur les Mod√®les :**\n",
    "\n",
    "#### **Mod√®les Sensibles (n√©cessitent scaling) :**\n",
    "\n",
    "- **R√©gression Logistique** : les gros coefficients dominent\n",
    "- **SVM** : calcul de distances biais√©\n",
    "- **R√©seaux de Neurones** : convergence difficile\n",
    "- **K-NN** : distances fauss√©es\n",
    "\n",
    "#### **Mod√®les Insensibles (peuvent fonctionner sans) :**\n",
    "\n",
    "- **Random Forest** : split sur seuils, pas de calcul de distance\n",
    "- **XGBoost / LightGBM** : idem\n",
    "- **Decision Trees** : idem\n",
    "\n",
    "**Mais :** M√™me pour les tree-based, le scaling peut **acc√©l√©rer** la convergence et am√©liorer l√©g√®rement les performances.\n",
    "\n",
    "### **9.2 Technique : StandardScaler**\n",
    "\n",
    "**Formule :**\n",
    "\n",
    "```\n",
    "scaled_value = (value - mean) / std\n",
    "```\n",
    "\n",
    "**R√©sultat :**\n",
    "\n",
    "```\n",
    "Moyenne (¬µ) = 0\n",
    "√âcart-type (œÉ) = 1\n",
    "```\n",
    "\n",
    "**Exemple :**\n",
    "\n",
    "```\n",
    "AMT_CREDIT original : [10K, 50K, 100K]\n",
    "Moyenne = 53.3K\n",
    "Std = 36.9K\n",
    "\n",
    "AMT_CREDIT scaled :\n",
    "(10K - 53.3K) / 36.9K = -1.17\n",
    "(50K - 53.3K) / 36.9K = -0.09\n",
    "(100K - 53.3K) / 36.9K = 1.27\n",
    "\n",
    "‚Üí Distribution centr√©e sur 0, dispers√©e autour de ¬±1\n",
    "```\n",
    "\n",
    "### **9.3 Colonnes √† Scaler**\n",
    "\n",
    "```python\n",
    "cols_to_scale = [col for col in train.columns if col not in ['SK_ID_CURR', 'TARGET']]\n",
    "```\n",
    "\n",
    "**Ne JAMAIS scaler :**\n",
    "\n",
    "- `SK_ID_CURR` : identifiant, pas une feature\n",
    "- `TARGET` : variable √† pr√©dire, doit rester en 0/1\n",
    "\n",
    "### **9.4 Fit vs Transform : CRUCIAL pour √âviter le Data Leakage**\n",
    "\n",
    "**Processus Correct :**\n",
    "\n",
    "```python\n",
    "# 1. Fit sur TRAIN uniquement\n",
    "scaler.fit(train[cols_to_scale])\n",
    "\n",
    "# 2. Transform train\n",
    "train_scaled = scaler.transform(train[cols_to_scale])\n",
    "\n",
    "# 3. Transform test (avec les param√®tres du train !)\n",
    "test_scaled = scaler.transform(test[cols_to_scale])\n",
    "```\n",
    "\n",
    "**Pourquoi Fit Uniquement sur Train ?**\n",
    "\n",
    "**Mauvaise Approche (Data Leakage) :**\n",
    "\n",
    "```python\n",
    "# FIT sur train + test combin√©s\n",
    "all_data = pd.concat([train, test])\n",
    "scaler.fit(all_data)  # ‚ùå ERREUR !\n",
    "\n",
    "# Les statistiques (mean, std) incluent le test\n",
    "# ‚Üí Information du test \"fuit\" dans le train\n",
    "# ‚Üí R√©sultats optimistes mais invalides en production\n",
    "```\n",
    "\n",
    "**Bonne Approche :**\n",
    "\n",
    "```python\n",
    "# FIT uniquement sur train\n",
    "scaler.fit(train)\n",
    "\n",
    "# TRANSFORM train et test\n",
    "# Test utilise les param√®tres calcul√©s sur train uniquement\n",
    "```\n",
    "\n",
    "**Analogie :**\n",
    "\n",
    "C'est comme un examen :\n",
    "\n",
    "- ‚ùå **Mauvais :** Tu r√©vises avec le sujet de l'examen inclus\n",
    "- ‚úÖ **Bon :** Tu r√©vises sans conna√Ætre le sujet exact\n",
    "\n",
    "### **9.5 Sauvegarde du Scaler**\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "```\n",
    "\n",
    "**Pourquoi Sauvegarder ?**\n",
    "\n",
    "**En production, les nouvelles donn√©es devront √™tre scal√©es EXACTEMENT pareil :**\n",
    "\n",
    "```python\n",
    "# En production\n",
    "new_client = pd.DataFrame([...])\n",
    "\n",
    "# Charger le scaler entra√Æn√©\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Appliquer LA M√äME transformation\n",
    "new_client_scaled = scaler.transform(new_client)\n",
    "\n",
    "# Pr√©dire\n",
    "prediction = model.predict(new_client_scaled)\n",
    "```\n",
    "\n",
    "Si on ne sauvegarde pas le scaler, on devra le recalculer ‚Üí les param√®tres seront diff√©rents ‚Üí pr√©dictions fausses !\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **PARTIE 10 : V√âRIFICATIONS FINALES**\n",
    "\n",
    "### **10.1 Checklist Compl√®te**\n",
    "\n",
    "| V√©rification              | Attendu        | Critique     |\n",
    "| ------------------------- | -------------- | ------------ |\n",
    "| **NaN train**             | 0              | ‚úÖ CRITIQUE  |\n",
    "| **NaN test**              | 0              | ‚úÖ CRITIQUE  |\n",
    "| **Inf train**             | 0              | ‚úÖ CRITIQUE  |\n",
    "| **Inf test**              | 0              | ‚úÖ CRITIQUE  |\n",
    "| **Mean scaled**           | ‚âà 0            | ‚ö†Ô∏è Important |\n",
    "| **Std scaled**            | ‚âà 1            | ‚ö†Ô∏è Important |\n",
    "| **Colonnes train = test** | Oui            | ‚úÖ CRITIQUE  |\n",
    "| **TARGET inchang√©e**      | 0/1 uniquement | ‚úÖ CRITIQUE  |\n",
    "\n",
    "### **10.2 V√©rification des Distributions**\n",
    "\n",
    "**Avant Scaling :**\n",
    "\n",
    "```\n",
    "AMT_CREDIT : mean = 53,333, std = 36,987\n",
    "AGE_YEARS : mean = 43.6, std = 11.3\n",
    "```\n",
    "\n",
    "**Apr√®s Scaling :**\n",
    "\n",
    "```\n",
    "AMT_CREDIT_scaled : mean ‚âà 0.000001, std ‚âà 1.000\n",
    "AGE_YEARS_scaled : mean ‚âà 0.000002, std ‚âà 1.000\n",
    "```\n",
    "\n",
    "**Si mean pas exactement 0 :** C'est normal (erreurs d'arrondi flottant), tant que c'est proche de 0.\n",
    "\n",
    "---\n",
    "\n",
    "## üíæ **PARTIE 11 : SAUVEGARDE & OUTPUTS**\n",
    "\n",
    "Une partie suppl√©mentaire a √©t√© rajout√©e pour clean le nom des colonnes du dataset.\n",
    "\n",
    "### üîç Le Probl√®me\n",
    "\n",
    "LightGBMError: Do not support special JSON characters in feature name.\n",
    "LightGBM est TR√àS strict sur les noms de colonnes. Il refuse :\n",
    "\n",
    "Espaces : NAME_CONTRACT_TYPE_Cash loans ‚ùå\n",
    "Apostrophes : NAME_TYPE_SUITE_Unaccompanied ‚ùå\n",
    "Caract√®res sp√©ciaux : [, ], {, }, :, , ‚ùå\n",
    "\n",
    "Ces noms proviennent du One-Hot Encoding du Notebook 2 qui a cr√©√© des colonnes comme :\n",
    "\n",
    "NAME_CONTRACT_TYPE_Cash loans (espace!)\n",
    "Autres colonnes avec caract√®res sp√©ciaux\n",
    "\n",
    "Maintenant, train_preprocessed.csv et test_preprocessed.csv auront des noms de colonnes compatibles avec tous les algorithmes (LogReg, RF, XGBoost, LightGBM).\n",
    "\n",
    "### **11.1 Fichiers Sauvegard√©s**\n",
    "\n",
    "| Fichier                  | Contenu                                                | Utilisation                                  |\n",
    "| ------------------------ | ------------------------------------------------------ | -------------------------------------------- |\n",
    "| `train_preprocessed.csv` | (307,511 √ó ~265)<br>0 NaN, tout scal√©, features cr√©√©es | **Notebook 3** : entra√Ænement MLFlow         |\n",
    "| `test_preprocessed.csv`  | (48,744 √ó ~265)<br>Idem que train                      | **Notebook 3** : pr√©dictions finales         |\n",
    "| `scaler.pkl`             | Objet StandardScaler fit√© sur train                    | **Production** : scaler de nouvelles donn√©es |\n",
    "\n",
    "### **11.2 M√©tadonn√©es √† Documenter**\n",
    "\n",
    "```\n",
    "üìä PREPROCESSING SUMMARY\n",
    "\n",
    "Input:\n",
    "- train_aggregated.csv : 307,511 √ó 305\n",
    "- test_aggregated.csv : 48,744 √ó 304\n",
    "\n",
    "Transformations:\n",
    "1. Features \"Has_History\" : +5 colonnes\n",
    "2. Suppression >80% NaN : -45 colonnes\n",
    "3. One-Hot Encoding : -15 cat, +25 binaires\n",
    "4. Imputation : 0 NaN restants\n",
    "5. Feature Engineering : +11 colonnes\n",
    "6. Scaling : mean=0, std=1\n",
    "\n",
    "Output:\n",
    "- train_preprocessed.csv : 307,511 √ó 265\n",
    "- test_preprocessed.csv : 48,744 √ó 265\n",
    "- scaler.pkl\n",
    "\n",
    "Stats:\n",
    "- 0 NaN\n",
    "- 0 Inf\n",
    "- Colonnes align√©es train/test\n",
    "- TARGET pr√©serv√©e\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **STRAT√âGIES GLOBALES MISES EN PLACE**\n",
    "\n",
    "### **Strat√©gie 1 : Pr√©servation de l'Information**\n",
    "\n",
    "```\n",
    "Avant de SUPPRIMER ou TRANSFORMER quoi que ce soit,\n",
    "on CAPTURE l'information dans de nouvelles features.\n",
    "\n",
    "Exemple : HAS_BUREAU avant d'imputer les NaN\n",
    "```\n",
    "\n",
    "### **Strat√©gie 2 : Traitement Diff√©renci√© par Type**\n",
    "\n",
    "```\n",
    "Pas de \"one size fits all\" :\n",
    "- Montants ‚Üí 0\n",
    "- Dates ‚Üí -999\n",
    "- Moyennes ‚Üí m√©diane\n",
    "- etc.\n",
    "\n",
    "Chaque type s√©mantique a SA strat√©gie.\n",
    "```\n",
    "\n",
    "### **Strat√©gie 3 : Feature Engineering Guid√© par le M√©tier**\n",
    "\n",
    "```\n",
    "On ne cr√©e pas n'importe quel ratio.\n",
    "On cr√©e des features qui ont du SENS m√©tier :\n",
    "\n",
    "‚úÖ CREDIT_INCOME_RATIO ‚Üí r√®gle des 33%\n",
    "‚úÖ ANNUITY_INCOME_RATIO ‚Üí capacit√© de remboursement\n",
    "‚ùå (DAYS_BIRTH √ó CNT_CHILDREN) ‚Üí non sens !\n",
    "```\n",
    "\n",
    "### **Strat√©gie 4 : Robustesse aux Outliers**\n",
    "\n",
    "```\n",
    "M√©diane plut√¥t que moyenne ‚Üí robuste\n",
    "StandardScaler ‚Üí g√®re les outliers mieux que MinMaxScaler\n",
    "+1 dans d√©nominateurs ‚Üí √©vite divisions par 0\n",
    "```\n",
    "\n",
    "### **Strat√©gie 5 : Reproductibilit√© Totale**\n",
    "\n",
    "```\n",
    "Tout est scriptable, automatique, reproductible :\n",
    "- fit sur train, transform sur test\n",
    "- scaler sauvegard√©\n",
    "- Aucune intervention manuelle\n",
    "```\n",
    "\n",
    "### **Strat√©gie 6 : Pr√©vention du Data Leakage**\n",
    "\n",
    "```\n",
    "JAMAIS d'information du test dans le train :\n",
    "- Scaler fit√© uniquement sur train\n",
    "- Imputation calcul√©e sur train\n",
    "- Tout param√©trage sur train\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **R√âSUM√â EN CHIFFRES**\n",
    "\n",
    "### **Avant Preprocessing**\n",
    "\n",
    "```\n",
    "train_aggregated.csv : 307,511 √ó 305\n",
    "- 250 colonnes avec NaN (82%)\n",
    "- 15 colonnes cat√©gorielles\n",
    "- √âchelles : [0-1] √† [0-500,000]\n",
    "- Aucune feature d√©riv√©e\n",
    "```\n",
    "\n",
    "### **Apr√®s Preprocessing**\n",
    "\n",
    "```\n",
    "train_preprocessed.csv : 307,511 √ó 265\n",
    "- 0 NaN (0%)\n",
    "- 0 colonnes cat√©gorielles (tout encod√©)\n",
    "- √âchelles : toutes centr√©es (mean‚âà0, std‚âà1)\n",
    "- +11 features d√©riv√©es\n",
    "- -45 colonnes supprim√©es (>80% NaN)\n",
    "- +5 features \"Has_History\"\n",
    "```\n",
    "\n",
    "### **Gain M√©tier**\n",
    "\n",
    "```\n",
    "‚úÖ Dataset propre, utilisable par n'importe quel algo ML\n",
    "‚úÖ Features m√©tier capturant les patterns importants\n",
    "‚úÖ Gestion intelligente des NaN (pas de perte d'info)\n",
    "‚úÖ Reproductibilit√© garantie (scaler.pkl)\n",
    "‚úÖ Pr√™t pour MLOps (tracking, serving)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéì **POINTS CL√âS √Ä RETENIR POUR TON EXPLICATION**\n",
    "\n",
    "### **1. La S√©quence Compte !**\n",
    "\n",
    "```\n",
    "1. HAS_HISTORY d'abord (avant imputation)\n",
    "2. Suppression colonnes >80% NaN\n",
    "3. Encodage cat√©gorielles\n",
    "4. Imputation (5 strat√©gies)\n",
    "5. Feature Engineering\n",
    "6. Gestion inf\n",
    "7. Scaling\n",
    "8. V√©rifications\n",
    "9. Sauvegarde\n",
    "```\n",
    "\n",
    "**Changer l'ordre = casser la logique !**\n",
    "\n",
    "### **2. Les NaN ne Sont Pas des Erreurs**\n",
    "\n",
    "```\n",
    "NaN = absence d'historique\n",
    "‚Üí Information pr√©cieuse !\n",
    "‚Üí On la capture (HAS_HISTORY) avant de la \"perdre\"\n",
    "```\n",
    "\n",
    "### **3. L'Imputation n'est Pas Arbitraire**\n",
    "\n",
    "```\n",
    "5 strat√©gies diff√©rentes selon la s√©mantique :\n",
    "- Montant ‚Üí 0\n",
    "- Comptage ‚Üí 0\n",
    "- Date ‚Üí -999\n",
    "- Moyenne ‚Üí m√©diane\n",
    "- Autre ‚Üí m√©diane\n",
    "```\n",
    "\n",
    "### **4. Le Feature Engineering Est M√©tier**\n",
    "\n",
    "```\n",
    "Pas de \"ratio random\" :\n",
    "‚úÖ Features avec sens m√©tier\n",
    "‚úÖ Bas√©es sur r√®gles bancaires\n",
    "‚úÖ Capturent patterns que le mod√®le aurait du mal √† voir\n",
    "```\n",
    "\n",
    "### **5. Le Scaling Est Essentiel**\n",
    "\n",
    "```\n",
    "Fit sur train, transform sur train+test\n",
    "Sauvegarder le scaler pour la prod\n",
    "Mean‚âà0, Std‚âà1 pour tous les algos\n",
    "```\n",
    "\n",
    "### **6. Data Leakage = Ennemi #1**\n",
    "\n",
    "```\n",
    "JAMAIS d'info du test dans le train :\n",
    "‚ùå fit sur train+test\n",
    "‚úÖ fit sur train uniquement\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ **CE QU'ON PEUT FAIRE MAINTENANT**\n",
    "\n",
    "Avec `train_preprocessed.csv`, on peut :\n",
    "\n",
    "1. ‚úÖ **Entra√Æner n'importe quel mod√®le ML** sans erreur\n",
    "2. ‚úÖ **Utiliser MLFlow** pour tracker les exp√©rimentations\n",
    "3. ‚úÖ **Cr√©er le score m√©tier personnalis√©** (Notebook 3)\n",
    "4. ‚úÖ **Optimiser les hyperparam√®tres** (GridSearchCV)\n",
    "5. ‚úÖ **Optimiser le seuil de d√©cision** (maximiser le score m√©tier)\n",
    "6. ‚úÖ **Comparer les mod√®les** sur des bases saines\n",
    "7. ‚úÖ **D√©ployer en production** (avec scaler.pkl)\n",
    "\n",
    "---\n",
    "\n",
    "**Voil√† Pierre ! Tu as maintenant un r√©sum√© ultra-d√©taill√© du Notebook 2. Tu peux expliquer chaque d√©cision, chaque strat√©gie, et montrer que c'est du preprocessing **professionnel** et **r√©fl√©chi**. Pr√™t pour le Notebook 3 (MLFlow + Score M√©tier) ? üéØ**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
